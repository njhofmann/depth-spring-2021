using cuda
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): DepthConv'>(64, 64, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv1_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): DepthConv'>(64, 64, kernel_size=(3, 3), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(1, 1), bias=None)
      (conv2_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): DepthConv'>(64, 256, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv3_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): DepthConv'>(256, 64, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv1_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): DepthConv'>(64, 64, kernel_size=(3, 3), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(1, 1), bias=None)
      (conv2_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): DepthConv'>(64, 256, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv3_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): DepthConv'>(256, 64, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv1_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): DepthConv'>(64, 64, kernel_size=(3, 3), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(1, 1), bias=None)
      (conv2_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): DepthConv'>(64, 256, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv3_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): DepthConv'>(256, 128, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv1_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): DepthConv'>(128, 128, kernel_size=(3, 3), alpha=8.3,dilation=(1, 1), stride=(2, 2),padding=(1, 1), bias=None)
      (conv2_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): DepthConv'>(128, 512, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv3_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): DepthConv'>(512, 128, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv1_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): DepthConv'>(128, 128, kernel_size=(3, 3), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(1, 1), bias=None)
      (conv2_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): DepthConv'>(128, 512, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv3_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): DepthConv'>(512, 128, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv1_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): DepthConv'>(128, 128, kernel_size=(3, 3), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(1, 1), bias=None)
      (conv2_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): DepthConv'>(128, 512, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv3_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): DepthConv'>(512, 128, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv1_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): DepthConv'>(128, 128, kernel_size=(3, 3), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(1, 1), bias=None)
      (conv2_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): DepthConv'>(128, 512, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv3_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): DepthConv'>(512, 256, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv1_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): DepthConv'>(256, 256, kernel_size=(3, 3), alpha=8.3,dilation=(1, 1), stride=(2, 2),padding=(1, 1), bias=None)
      (conv2_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): DepthConv'>(256, 1024, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv3_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): DepthConv'>(1024, 256, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv1_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): DepthConv'>(256, 256, kernel_size=(3, 3), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(1, 1), bias=None)
      (conv2_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): DepthConv'>(256, 1024, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv3_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): DepthConv'>(1024, 256, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv1_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): DepthConv'>(256, 256, kernel_size=(3, 3), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(1, 1), bias=None)
      (conv2_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): DepthConv'>(256, 1024, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv3_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): DepthConv'>(1024, 256, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv1_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): DepthConv'>(256, 256, kernel_size=(3, 3), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(1, 1), bias=None)
      (conv2_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): DepthConv'>(256, 1024, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv3_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): DepthConv'>(1024, 256, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv1_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): DepthConv'>(256, 256, kernel_size=(3, 3), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(1, 1), bias=None)
      (conv2_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): DepthConv'>(256, 1024, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv3_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): DepthConv'>(1024, 256, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv1_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): DepthConv'>(256, 256, kernel_size=(3, 3), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(1, 1), bias=None)
      (conv2_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): DepthConv'>(256, 1024, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv3_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): DepthConv'>(1024, 512, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv1_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): DepthConv'>(512, 512, kernel_size=(3, 3), alpha=8.3,dilation=(1, 1), stride=(2, 2),padding=(1, 1), bias=None)
      (conv2_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): DepthConv'>(512, 2048, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv3_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): DepthConv'>(2048, 512, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv1_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): DepthConv'>(512, 512, kernel_size=(3, 3), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(1, 1), bias=None)
      (conv2_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): DepthConv'>(512, 2048, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv3_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): DepthConv'>(2048, 512, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv1_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): DepthConv'>(512, 512, kernel_size=(3, 3), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(1, 1), bias=None)
      (conv2_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): DepthConv'>(512, 2048, kernel_size=(1, 1), alpha=8.3,dilation=(1, 1), stride=(1, 1),padding=(0, 0), bias=None)
      (conv3_depth_avger): AvgPool2d(kernel_size=3, stride=2, padding=1)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=1000, bias=True)
)
epoch 0
iteration: 50, loss: 2.574101448059082
iteration: 100, loss: 2.6353588104248047
iteration: 150, loss: 2.425276041030884
iteration: 200, loss: 2.846482992172241
iteration: 250, loss: 2.2282347679138184
iteration: 300, loss: 2.1014506816864014
iteration: 350, loss: 1.9094932079315186
iteration: 400, loss: 2.121785879135132
iteration: 450, loss: 1.9555118083953857
iteration: 500, loss: 2.291656494140625
iteration: 550, loss: 1.971213936805725
iteration: 600, loss: 1.9999831914901733
iteration: 650, loss: 2.0471322536468506
iteration: 700, loss: 1.5979644060134888
iteration: 750, loss: 2.0652456283569336
iteration: 800, loss: 2.2850546836853027
iteration: 850, loss: 2.3850643634796143
iteration: 900, loss: 2.322807550430298
iteration: 950, loss: 2.1886613368988037
iteration: 1000, loss: 2.2251644134521484
iteration: 1050, loss: 2.091226816177368
iteration: 1100, loss: 1.8474549055099487
iteration: 1150, loss: 1.757483959197998
iteration: 1200, loss: 2.097214698791504
iteration: 1250, loss: 2.4434611797332764
iteration: 1300, loss: 2.5913522243499756
epoch 0, loss: 2.2086047893441165
epoch 1
iteration: 1350, loss: 2.1677041053771973
iteration: 1400, loss: 2.0618374347686768
iteration: 1450, loss: 1.9101523160934448
iteration: 1500, loss: 2.1300296783447266
iteration: 1550, loss: 2.3169541358947754
iteration: 1600, loss: 1.4696946144104004
iteration: 1650, loss: 2.012580633163452
iteration: 1700, loss: 1.7221449613571167
iteration: 1750, loss: 2.5646615028381348
iteration: 1800, loss: 2.469305992126465
iteration: 1850, loss: 2.0709335803985596
iteration: 1900, loss: 2.3497159481048584
iteration: 1950, loss: 1.8740986585617065
iteration: 2000, loss: 2.1855220794677734
iteration: 2050, loss: 1.8035653829574585
iteration: 2100, loss: 1.9903764724731445
iteration: 2150, loss: 1.5465030670166016
iteration: 2200, loss: 2.196425199508667
iteration: 2250, loss: 1.968348503112793
iteration: 2300, loss: 2.2783279418945312
iteration: 2350, loss: 1.746368408203125
iteration: 2400, loss: 2.029430627822876
iteration: 2450, loss: 2.2171192169189453
iteration: 2500, loss: 2.134458065032959
iteration: 2550, loss: 1.9002623558044434
iteration: 2600, loss: 1.616136074066162
epoch 1, loss: 2.0379649004399383
epoch 2
iteration: 2650, loss: 2.0668962001800537
iteration: 2700, loss: 2.089858055114746
iteration: 2750, loss: 1.9569979906082153
iteration: 2800, loss: 2.359779119491577
iteration: 2850, loss: 1.7971689701080322
iteration: 2900, loss: 2.330629348754883
iteration: 2950, loss: 1.8779443502426147
iteration: 3000, loss: 2.2434821128845215
iteration: 3050, loss: 1.8815503120422363
iteration: 3100, loss: 1.8290269374847412
iteration: 3150, loss: 2.37446928024292
iteration: 3200, loss: 2.0913708209991455
iteration: 3250, loss: 1.6911262273788452
iteration: 3300, loss: 1.5958009958267212
iteration: 3350, loss: 1.852688193321228
iteration: 3400, loss: 2.3586604595184326
iteration: 3450, loss: 1.9511889219284058
iteration: 3500, loss: 2.1272881031036377
iteration: 3550, loss: 1.7571474313735962
iteration: 3600, loss: 1.7295753955841064
iteration: 3650, loss: 1.787734866142273
iteration: 3700, loss: 1.9368813037872314
iteration: 3750, loss: 1.1891727447509766
iteration: 3800, loss: 1.9008920192718506
iteration: 3850, loss: 2.0866315364837646
iteration: 3900, loss: 1.9822484254837036
iteration: 3950, loss: 1.7759816646575928
epoch 2, loss: 1.9636428577672116
epoch 3
iteration: 4000, loss: 1.5651298761367798
iteration: 4050, loss: 1.6279367208480835
iteration: 4100, loss: 1.9884419441223145
iteration: 4150, loss: 2.0864741802215576
iteration: 4200, loss: 1.7876815795898438
iteration: 4250, loss: 2.034837245941162
iteration: 4300, loss: 1.954689383506775
iteration: 4350, loss: 1.903559923171997
iteration: 4400, loss: 2.3191258907318115
iteration: 4450, loss: 1.807153344154358
iteration: 4500, loss: 1.6095830202102661
iteration: 4550, loss: 1.3598679304122925
iteration: 4600, loss: 1.7897100448608398
iteration: 4650, loss: 2.2762186527252197
iteration: 4700, loss: 2.3908543586730957
iteration: 4750, loss: 1.6983329057693481
iteration: 4800, loss: 1.8880953788757324
iteration: 4850, loss: 2.3480403423309326
iteration: 4900, loss: 2.3753247261047363
iteration: 4950, loss: 2.1238017082214355
iteration: 5000, loss: 1.9209949970245361
iteration: 5050, loss: 1.5698754787445068
iteration: 5100, loss: 2.1231484413146973
iteration: 5150, loss: 1.5481160879135132
iteration: 5200, loss: 1.7404837608337402
iteration: 5250, loss: 1.8204745054244995
epoch 3, loss: 1.916793604176791
epoch 4
iteration: 5300, loss: 2.070086717605591
iteration: 5350, loss: 2.415100336074829
iteration: 5400, loss: 1.78553307056427
iteration: 5450, loss: 1.5758205652236938
iteration: 5500, loss: 1.6847562789916992
iteration: 5550, loss: 1.8964987993240356
iteration: 5600, loss: 1.56313157081604
iteration: 5650, loss: 1.4808834791183472
iteration: 5700, loss: 1.9443196058273315
iteration: 5750, loss: 2.585693120956421
iteration: 5800, loss: 1.6886214017868042
iteration: 5850, loss: 1.6178698539733887
iteration: 5900, loss: 1.6927489042282104
iteration: 5950, loss: 2.2653894424438477
iteration: 6000, loss: 2.4246363639831543
iteration: 6050, loss: 1.6934196949005127
iteration: 6100, loss: 1.8102436065673828
iteration: 6150, loss: 2.542001724243164
iteration: 6200, loss: 1.837814211845398
iteration: 6250, loss: 1.5748481750488281
iteration: 6300, loss: 1.9982633590698242
iteration: 6350, loss: 1.7318577766418457
iteration: 6400, loss: 1.6520612239837646
iteration: 6450, loss: 1.6322132349014282
iteration: 6500, loss: 1.5660375356674194
iteration: 6550, loss: 2.187903642654419
iteration: 6600, loss: 2.5278961658477783
epoch 4, loss: 1.880244177021615
epoch 5
iteration: 6650, loss: 2.5363926887512207
iteration: 6700, loss: 2.4326226711273193
iteration: 6750, loss: 1.8294248580932617
iteration: 6800, loss: 1.8643827438354492
iteration: 6850, loss: 1.8570722341537476
iteration: 6900, loss: 1.8986759185791016
iteration: 6950, loss: 1.4422563314437866
iteration: 7000, loss: 2.4715309143066406
iteration: 7050, loss: 1.8262690305709839
iteration: 7100, loss: 1.3443642854690552
iteration: 7150, loss: 1.4813830852508545
iteration: 7200, loss: 1.8071755170822144
iteration: 7250, loss: 1.7937662601470947
iteration: 7300, loss: 1.7317888736724854
iteration: 7350, loss: 1.347936987876892
iteration: 7400, loss: 1.378088355064392
iteration: 7450, loss: 1.4448392391204834
iteration: 7500, loss: 2.3642756938934326
iteration: 7550, loss: 2.002366542816162
iteration: 7600, loss: 1.9141106605529785
iteration: 7650, loss: 1.6420564651489258
iteration: 7700, loss: 1.6958503723144531
iteration: 7750, loss: 2.0631256103515625
iteration: 7800, loss: 2.101969003677368
iteration: 7850, loss: 1.7986664772033691
iteration: 7900, loss: 1.7578834295272827
epoch 5, loss: 1.8577588347522516
epoch 6
iteration: 7950, loss: 1.9578912258148193
iteration: 8000, loss: 2.4652326107025146
iteration: 8050, loss: 1.5387158393859863
iteration: 8100, loss: 1.8019698858261108
iteration: 8150, loss: 1.6113059520721436
iteration: 8200, loss: 1.556999683380127
iteration: 8250, loss: 2.0617995262145996
iteration: 8300, loss: 2.5803589820861816
iteration: 8350, loss: 2.144092321395874
iteration: 8400, loss: 1.8905044794082642
iteration: 8450, loss: 1.8209174871444702
iteration: 8500, loss: 2.1106467247009277
iteration: 8550, loss: 2.2806479930877686
iteration: 8600, loss: 1.334542155265808
iteration: 8650, loss: 1.5535805225372314
iteration: 8700, loss: 1.887160062789917
iteration: 8750, loss: 1.74830961227417
iteration: 8800, loss: 1.3466928005218506
iteration: 8850, loss: 2.141040802001953
iteration: 8900, loss: 1.4041000604629517
iteration: 8950, loss: 2.0307583808898926
iteration: 9000, loss: 1.8794747591018677
iteration: 9050, loss: 1.6565217971801758
iteration: 9100, loss: 1.2488572597503662
iteration: 9150, loss: 1.685388445854187
iteration: 9200, loss: 1.7018897533416748
epoch 6, loss: 1.826878492180311
epoch 7
iteration: 9250, loss: 1.7760586738586426
iteration: 9300, loss: 1.8069055080413818
iteration: 9350, loss: 1.7320055961608887
iteration: 9400, loss: 1.6412990093231201
iteration: 9450, loss: 2.0096075534820557
iteration: 9500, loss: 1.6825400590896606
iteration: 9550, loss: 1.7412832975387573
iteration: 9600, loss: 1.4717488288879395
iteration: 9650, loss: 2.1665875911712646
iteration: 9700, loss: 1.5223489999771118
iteration: 9750, loss: 2.0558841228485107
iteration: 9800, loss: 2.6704981327056885
iteration: 9850, loss: 2.38110089302063
iteration: 9900, loss: 1.6392508745193481
iteration: 9950, loss: 1.7806636095046997
iteration: 10000, loss: 1.8100438117980957
iteration: 10050, loss: 2.4304020404815674
iteration: 10100, loss: 1.7465170621871948
iteration: 10150, loss: 1.6942108869552612
iteration: 10200, loss: 1.599496841430664
iteration: 10250, loss: 1.912009835243225
iteration: 10300, loss: 1.2773140668869019
iteration: 10350, loss: 1.861015796661377
iteration: 10400, loss: 1.4861831665039062
iteration: 10450, loss: 1.3400882482528687
iteration: 10500, loss: 1.7703403234481812
iteration: 10550, loss: 1.5569461584091187
epoch 7, loss: 1.810878732188648
epoch 8
iteration: 10600, loss: 2.081763982772827
iteration: 10650, loss: 1.8977142572402954
iteration: 10700, loss: 1.3639702796936035
iteration: 10750, loss: 1.8813639879226685
iteration: 10800, loss: 2.008270263671875
iteration: 10850, loss: 1.8526886701583862
iteration: 10900, loss: 2.9065983295440674
iteration: 10950, loss: 1.6906682252883911
iteration: 11000, loss: 2.133063793182373
iteration: 11050, loss: 1.2558927536010742
iteration: 11100, loss: 1.910620093345642
iteration: 11150, loss: 2.1134679317474365
iteration: 11200, loss: 1.425201654434204
iteration: 11250, loss: 2.0062174797058105
iteration: 11300, loss: 1.6578547954559326
iteration: 11350, loss: 2.139770984649658
iteration: 11400, loss: 1.8009589910507202
iteration: 11450, loss: 1.670290470123291
iteration: 11500, loss: 1.6729463338851929
iteration: 11550, loss: 1.6581355333328247
iteration: 11600, loss: 1.8302898406982422
iteration: 11650, loss: 2.0369467735290527
iteration: 11700, loss: 2.238116502761841
iteration: 11750, loss: 1.9701577425003052
iteration: 11800, loss: 1.6000816822052002
iteration: 11850, loss: 1.9964393377304077
epoch 8, loss: 1.794289027099465
epoch 9
iteration: 11900, loss: 1.8459960222244263
iteration: 11950, loss: 2.162876605987549
iteration: 12000, loss: 2.3459253311157227
iteration: 12050, loss: 1.5979353189468384
iteration: 12100, loss: 1.8075413703918457
iteration: 12150, loss: 1.7252637147903442
iteration: 12200, loss: 1.7430497407913208
iteration: 12250, loss: 2.291304111480713
iteration: 12300, loss: 1.6952520608901978
iteration: 12350, loss: 1.4782774448394775
iteration: 12400, loss: 1.5698332786560059
iteration: 12450, loss: 1.6970547437667847
iteration: 12500, loss: 1.352690577507019
iteration: 12550, loss: 2.0433950424194336
iteration: 12600, loss: 2.1239893436431885
iteration: 12650, loss: 1.726341724395752
iteration: 12700, loss: 1.616788625717163
iteration: 12750, loss: 1.9643560647964478
iteration: 12800, loss: 2.01644229888916
iteration: 12850, loss: 1.864600419998169
iteration: 12900, loss: 1.9046574831008911
iteration: 12950, loss: 2.116834878921509
iteration: 13000, loss: 2.3649349212646484
iteration: 13050, loss: 2.5170419216156006
iteration: 13100, loss: 2.0082638263702393
iteration: 13150, loss: 1.5337899923324585
iteration: 13200, loss: 2.0003254413604736
epoch 9, loss: 1.7756941496705603
epoch 10
iteration: 13250, loss: 1.7828547954559326
iteration: 13300, loss: 1.9845261573791504
iteration: 13350, loss: 2.101604461669922
iteration: 13400, loss: 1.587520956993103
iteration: 13450, loss: 1.455137848854065
iteration: 13500, loss: 1.8976037502288818
iteration: 13550, loss: 1.7221969366073608
iteration: 13600, loss: 1.673130989074707
iteration: 13650, loss: 1.3211294412612915
iteration: 13700, loss: 1.1356147527694702
iteration: 13750, loss: 1.5832979679107666
iteration: 13800, loss: 1.2998671531677246
iteration: 13850, loss: 1.808103322982788
iteration: 13900, loss: 1.7579491138458252
iteration: 13950, loss: 1.8286176919937134
iteration: 14000, loss: 2.0770370960235596
iteration: 14050, loss: 1.5659209489822388
iteration: 14100, loss: 1.6813602447509766
iteration: 14150, loss: 1.938483715057373
iteration: 14200, loss: 1.9262558221817017
iteration: 14250, loss: 1.976163387298584
iteration: 14300, loss: 1.2891751527786255
iteration: 14350, loss: 1.5022376775741577
iteration: 14400, loss: 1.8063673973083496
iteration: 14450, loss: 1.8995546102523804
iteration: 14500, loss: 1.617226004600525
epoch 10, loss: 1.7598102558753124
epoch 11
iteration: 14550, loss: 1.8010165691375732
iteration: 14600, loss: 1.9707552194595337
iteration: 14650, loss: 2.21397066116333
iteration: 14700, loss: 2.1568851470947266
iteration: 14750, loss: 1.714257836341858
iteration: 14800, loss: 1.6851845979690552
iteration: 14850, loss: 1.9834452867507935
iteration: 14900, loss: 1.306378722190857
iteration: 14950, loss: 1.5098124742507935
iteration: 15000, loss: 2.4855616092681885
iteration: 15050, loss: 1.7783232927322388
iteration: 15100, loss: 1.3250701427459717
iteration: 15150, loss: 1.6814857721328735
iteration: 15200, loss: 1.9626541137695312
iteration: 15250, loss: 1.5733646154403687
iteration: 15300, loss: 2.3784337043762207
iteration: 15350, loss: 2.5414321422576904
iteration: 15400, loss: 1.8787332773208618
iteration: 15450, loss: 1.812292456626892
iteration: 15500, loss: 1.571686863899231
iteration: 15550, loss: 1.4801989793777466
iteration: 15600, loss: 1.8775036334991455
iteration: 15650, loss: 2.0296058654785156
iteration: 15700, loss: 1.5748670101165771
iteration: 15750, loss: 2.582493543624878
iteration: 15800, loss: 1.870263695716858
iteration: 15850, loss: 1.664896011352539
epoch 11, loss: 1.755027659388229
epoch 12
iteration: 15900, loss: 2.0060510635375977
iteration: 15950, loss: 2.000530958175659
iteration: 16000, loss: 2.026413679122925
iteration: 16050, loss: 1.525407314300537
iteration: 16100, loss: 1.5057045221328735
iteration: 16150, loss: 2.236544609069824
iteration: 16200, loss: 1.8475267887115479
iteration: 16250, loss: 1.537741780281067
iteration: 16300, loss: 2.785372734069824
iteration: 16350, loss: 1.8498121500015259
iteration: 16400, loss: 1.6132886409759521
iteration: 16450, loss: 1.4991815090179443
iteration: 16500, loss: 1.8397141695022583
iteration: 16550, loss: 1.6128501892089844
iteration: 16600, loss: 1.8879690170288086
iteration: 16650, loss: 2.128166437149048
iteration: 16700, loss: 2.072646379470825
iteration: 16750, loss: 1.6527124643325806
iteration: 16800, loss: 1.6355785131454468
iteration: 16850, loss: 1.58134925365448
iteration: 16900, loss: 2.028390407562256
iteration: 16950, loss: 1.265574336051941
iteration: 17000, loss: 1.6938034296035767
iteration: 17050, loss: 1.497003197669983
iteration: 17100, loss: 1.9851468801498413
iteration: 17150, loss: 1.6126999855041504
epoch 12, loss: 1.743349752633664
epoch 13
iteration: 17200, loss: 2.0259504318237305
iteration: 17250, loss: 1.9429630041122437
iteration: 17300, loss: 2.1589713096618652
iteration: 17350, loss: 1.6894279718399048
iteration: 17400, loss: 2.019622802734375
iteration: 17450, loss: 1.7643818855285645
iteration: 17500, loss: 1.6609421968460083
iteration: 17550, loss: 1.5844759941101074
iteration: 17600, loss: 2.291991949081421
iteration: 17650, loss: 1.8131030797958374
iteration: 17700, loss: 1.6021997928619385
iteration: 17750, loss: 1.4308409690856934
iteration: 17800, loss: 2.0938336849212646
iteration: 17850, loss: 1.9816827774047852
iteration: 17900, loss: 1.6399517059326172
iteration: 17950, loss: 1.304387092590332
iteration: 18000, loss: 1.590803623199463
iteration: 18050, loss: 1.3788069486618042
iteration: 18100, loss: 1.5592859983444214
iteration: 18150, loss: 2.1612179279327393
iteration: 18200, loss: 1.8971728086471558
iteration: 18250, loss: 1.919661283493042
iteration: 18300, loss: 1.585015892982483
iteration: 18350, loss: 1.506299614906311
iteration: 18400, loss: 1.3423104286193848
iteration: 18450, loss: 1.6748896837234497
epoch 13, loss: 1.7192075987412554
epoch 14
iteration: 18500, loss: 1.613330364227295
iteration: 18550, loss: 1.7784868478775024
iteration: 18600, loss: 2.0840182304382324
iteration: 18650, loss: 1.4766813516616821
iteration: 18700, loss: 1.5805901288986206
iteration: 18750, loss: 1.5820462703704834
iteration: 18800, loss: 1.881200909614563
iteration: 18850, loss: 2.216583490371704
iteration: 18900, loss: 2.1369476318359375
iteration: 18950, loss: 1.4383814334869385
iteration: 19000, loss: 1.8485792875289917
iteration: 19050, loss: 1.3784555196762085
iteration: 19100, loss: 1.5925977230072021
iteration: 19150, loss: 1.7541112899780273
iteration: 19200, loss: 1.6961032152175903
iteration: 19250, loss: 1.83957839012146
iteration: 19300, loss: 1.5736089944839478
iteration: 19350, loss: 2.1707053184509277
iteration: 19400, loss: 1.5047959089279175
iteration: 19450, loss: 1.5417184829711914
iteration: 19500, loss: 1.5409963130950928
iteration: 19550, loss: 1.221779704093933
iteration: 19600, loss: 1.4644417762756348
iteration: 19650, loss: 1.7620335817337036
iteration: 19700, loss: 1.2398771047592163
iteration: 19750, loss: 1.281654715538025
iteration: 19800, loss: 2.0142533779144287
epoch 14, loss: 1.7174859648734302
epoch 15
iteration: 19850, loss: 2.380786180496216
iteration: 19900, loss: 1.8797297477722168
iteration: 19950, loss: 1.473789930343628
iteration: 20000, loss: 1.5373116731643677
iteration: 20050, loss: 1.3016481399536133
iteration: 20100, loss: 1.441340446472168
iteration: 20150, loss: 1.8104709386825562
iteration: 20200, loss: 1.6698064804077148
iteration: 20250, loss: 1.426175832748413
iteration: 20300, loss: 1.6228371858596802
iteration: 20350, loss: 1.517043113708496
iteration: 20400, loss: 1.9667505025863647
iteration: 20450, loss: 1.333047866821289
iteration: 20500, loss: 1.6027231216430664
iteration: 20550, loss: 1.6992290019989014
iteration: 20600, loss: 1.8772363662719727
iteration: 20650, loss: 1.6114161014556885
iteration: 20700, loss: 1.452566385269165
iteration: 20750, loss: 1.6103980541229248
iteration: 20800, loss: 1.7988781929016113
iteration: 20850, loss: 1.5176746845245361
iteration: 20900, loss: 1.581342339515686
iteration: 20950, loss: 2.1199452877044678
iteration: 21000, loss: 1.499169111251831
iteration: 21050, loss: 2.097107172012329
iteration: 21100, loss: 1.4022104740142822
epoch 15, loss: 1.7080668960975496
epoch 16
iteration: 21150, loss: 1.3618323802947998
iteration: 21200, loss: 1.5523991584777832
iteration: 21250, loss: 1.5176335573196411
iteration: 21300, loss: 2.340884208679199
iteration: 21350, loss: 2.111445665359497
iteration: 21400, loss: 1.5895434617996216
iteration: 21450, loss: 1.8428230285644531
iteration: 21500, loss: 2.88464093208313
iteration: 21550, loss: 1.9391655921936035
iteration: 21600, loss: 1.8503479957580566
iteration: 21650, loss: 1.4820820093154907
iteration: 21700, loss: 1.6893492937088013
iteration: 21750, loss: 1.6552094221115112
iteration: 21800, loss: 2.0384178161621094
iteration: 21850, loss: 1.5979008674621582
iteration: 21900, loss: 1.9918266534805298
iteration: 21950, loss: 1.870485782623291
iteration: 22000, loss: 1.5182069540023804
iteration: 22050, loss: 1.3203688859939575
iteration: 22100, loss: 1.2874170541763306
iteration: 22150, loss: 1.4876197576522827
iteration: 22200, loss: 1.374619960784912
iteration: 22250, loss: 1.7007403373718262
iteration: 22300, loss: 1.4450734853744507
iteration: 22350, loss: 2.06142520904541
iteration: 22400, loss: 1.776755690574646
iteration: 22450, loss: 1.2218382358551025
epoch 16, loss: 1.6888941364234196
epoch 17
iteration: 22500, loss: 1.732008695602417
iteration: 22550, loss: 1.9977177381515503
iteration: 22600, loss: 2.0268163681030273
iteration: 22650, loss: 2.1675214767456055
iteration: 22700, loss: 1.4433016777038574
iteration: 22750, loss: 1.5806983709335327
iteration: 22800, loss: 1.17131769657135
iteration: 22850, loss: 1.4335289001464844
iteration: 22900, loss: 1.928627610206604
iteration: 22950, loss: 1.593399167060852
iteration: 23000, loss: 1.5385762453079224
iteration: 23050, loss: 1.5660779476165771
iteration: 23100, loss: 1.7276629209518433
iteration: 23150, loss: 1.7193182706832886
iteration: 23200, loss: 1.5661180019378662
iteration: 23250, loss: 2.345700740814209
iteration: 23300, loss: 1.8805694580078125
iteration: 23350, loss: 1.8815438747406006
iteration: 23400, loss: 1.507006049156189
iteration: 23450, loss: 1.8343861103057861
iteration: 23500, loss: 1.5326454639434814
iteration: 23550, loss: 1.8327913284301758
iteration: 23600, loss: 1.7746045589447021
iteration: 23650, loss: 2.008171796798706
iteration: 23700, loss: 1.96172034740448
iteration: 23750, loss: 1.7747633457183838
epoch 17, loss: 1.6782284105060905
epoch 18
iteration: 23800, loss: 1.5849500894546509
iteration: 23850, loss: 1.610355019569397
iteration: 23900, loss: 1.6275516748428345
iteration: 23950, loss: 1.6016509532928467
iteration: 24000, loss: 1.550533652305603
iteration: 24050, loss: 1.4677430391311646
iteration: 24100, loss: 1.743450403213501
iteration: 24150, loss: 2.329453468322754
iteration: 24200, loss: 2.4526565074920654
iteration: 24250, loss: 1.5524240732192993
iteration: 24300, loss: 2.0958616733551025
iteration: 24350, loss: 1.6762785911560059
iteration: 24400, loss: 1.4095897674560547
iteration: 24450, loss: 1.2726911306381226
iteration: 24500, loss: 1.7436764240264893
iteration: 24550, loss: 1.5288844108581543
iteration: 24600, loss: 1.4336200952529907
iteration: 24650, loss: 1.7724491357803345
iteration: 24700, loss: 1.8253885507583618
iteration: 24750, loss: 1.3612875938415527
iteration: 24800, loss: 1.1794811487197876
iteration: 24850, loss: 2.2223424911499023
iteration: 24900, loss: 1.646548867225647
iteration: 24950, loss: 2.206822395324707
iteration: 25000, loss: 1.6879351139068604
iteration: 25050, loss: 2.186694860458374
epoch 18, loss: 1.6706502227819293
epoch 19
iteration: 25100, loss: 1.945996880531311
iteration: 25150, loss: 1.6493799686431885
iteration: 25200, loss: 1.6981487274169922
iteration: 25250, loss: 1.3883233070373535
iteration: 25300, loss: 1.7120475769042969
iteration: 25350, loss: 1.5784072875976562
iteration: 25400, loss: 1.7242581844329834
iteration: 25450, loss: 1.6728931665420532
iteration: 25500, loss: 1.3821829557418823
iteration: 25550, loss: 2.4200265407562256
iteration: 25600, loss: 1.4512407779693604
iteration: 25650, loss: 2.526204824447632
iteration: 25700, loss: 1.9662631750106812
iteration: 25750, loss: 1.9020498991012573
iteration: 25800, loss: 2.214982032775879
iteration: 25850, loss: 1.6183662414550781
iteration: 25900, loss: 2.490143299102783
iteration: 25950, loss: 1.0969443321228027
iteration: 26000, loss: 1.492488980293274
iteration: 26050, loss: 2.0823874473571777
iteration: 26100, loss: 1.5052711963653564
iteration: 26150, loss: 1.4818720817565918
iteration: 26200, loss: 1.5005027055740356
iteration: 26250, loss: 1.609086275100708
iteration: 26300, loss: 1.637734293937683
iteration: 26350, loss: 2.0796570777893066
iteration: 26400, loss: 1.5967775583267212
epoch 19, loss: 1.658621402134169
epoch 20
iteration: 26450, loss: 1.6314388513565063
iteration: 26500, loss: 1.73515784740448
iteration: 26550, loss: 1.4617365598678589
iteration: 26600, loss: 1.3368511199951172
iteration: 26650, loss: 1.591863989830017
iteration: 26700, loss: 2.3071818351745605
iteration: 26750, loss: 1.2524008750915527
iteration: 26800, loss: 1.716124176979065
iteration: 26850, loss: 1.896484136581421
iteration: 26900, loss: 1.1934019327163696
iteration: 26950, loss: 1.9489498138427734
iteration: 27000, loss: 1.513511061668396
iteration: 27050, loss: 1.107025384902954
iteration: 27100, loss: 1.8672573566436768
iteration: 27150, loss: 3.011892318725586
iteration: 27200, loss: 1.338895320892334
iteration: 27250, loss: 2.129197835922241
iteration: 27300, loss: 1.6175891160964966
iteration: 27350, loss: 1.6851308345794678
iteration: 27400, loss: 1.9452608823776245
iteration: 27450, loss: 1.7751706838607788
iteration: 27500, loss: 2.050868272781372
iteration: 27550, loss: 1.577620029449463
iteration: 27600, loss: 1.5604792833328247
iteration: 27650, loss: 1.727943778038025
iteration: 27700, loss: 1.8933430910110474
epoch 20, loss: 1.6528810102756901
epoch 21
iteration: 27750, loss: 1.9512027502059937
iteration: 27800, loss: 1.9836105108261108
iteration: 27850, loss: 1.5743387937545776
iteration: 27900, loss: 1.2229315042495728
iteration: 27950, loss: 1.9135481119155884
iteration: 28000, loss: 1.4339855909347534
iteration: 28050, loss: 1.8562103509902954
iteration: 28100, loss: 1.7732594013214111
iteration: 28150, loss: 1.3707444667816162
iteration: 28200, loss: 1.545883059501648
iteration: 28250, loss: 1.4537224769592285
iteration: 28300, loss: 1.2661924362182617
iteration: 28350, loss: 1.5343719720840454
iteration: 28400, loss: 2.2666916847229004
iteration: 28450, loss: 1.5716367959976196
iteration: 28500, loss: 2.0554187297821045
iteration: 28550, loss: 1.5625948905944824
iteration: 28600, loss: 1.7158584594726562
iteration: 28650, loss: 1.3147525787353516
iteration: 28700, loss: 1.9975234270095825
iteration: 28750, loss: 1.5948529243469238
iteration: 28800, loss: 1.4640133380889893
iteration: 28850, loss: 1.7061376571655273
iteration: 28900, loss: 1.2178521156311035
iteration: 28950, loss: 1.4320640563964844
iteration: 29000, loss: 1.6020452976226807
iteration: 29050, loss: 1.8635883331298828
epoch 21, loss: 1.6428872048911218
epoch 22
iteration: 29100, loss: 1.5198689699172974
iteration: 29150, loss: 1.6188840866088867
iteration: 29200, loss: 1.689788818359375
iteration: 29250, loss: 1.3514083623886108
iteration: 29300, loss: 2.1164710521698
iteration: 29350, loss: 1.9400562047958374
iteration: 29400, loss: 1.4610364437103271
iteration: 29450, loss: 2.076594114303589
iteration: 29500, loss: 2.06015682220459
iteration: 29550, loss: 1.6874476671218872
iteration: 29600, loss: 1.5987268686294556
iteration: 29650, loss: 2.31779146194458
iteration: 29700, loss: 1.4163639545440674
iteration: 29750, loss: 1.2519806623458862
iteration: 29800, loss: 1.5103058815002441
iteration: 29850, loss: 1.8076653480529785
iteration: 29900, loss: 1.2477110624313354
iteration: 29950, loss: 1.702581524848938
iteration: 30000, loss: 1.4592194557189941
iteration: 30050, loss: 1.9313381910324097
iteration: 30100, loss: 1.6496437788009644
iteration: 30150, loss: 1.61075758934021
iteration: 30200, loss: 1.7539726495742798
iteration: 30250, loss: 1.681020736694336
iteration: 30300, loss: 2.1890127658843994
iteration: 30350, loss: 1.481767177581787
epoch 22, loss: 1.6396767330259903
epoch 23
iteration: 30400, loss: 1.773061752319336
iteration: 30450, loss: 1.3657646179199219
iteration: 30500, loss: 1.7347729206085205
iteration: 30550, loss: 1.7400811910629272
iteration: 30600, loss: 1.9785971641540527
iteration: 30650, loss: 1.5116899013519287
iteration: 30700, loss: 1.8639494180679321
iteration: 30750, loss: 1.6622371673583984
iteration: 30800, loss: 1.8057382106781006
iteration: 30850, loss: 1.357354998588562
iteration: 30900, loss: 1.474504828453064
iteration: 30950, loss: 1.59003484249115
iteration: 31000, loss: 1.8615375757217407
iteration: 31050, loss: 1.8808114528656006
iteration: 31100, loss: 2.894232749938965
iteration: 31150, loss: 1.7443318367004395
iteration: 31200, loss: 1.9499839544296265
iteration: 31250, loss: 1.756951928138733
iteration: 31300, loss: 2.2721214294433594
iteration: 31350, loss: 2.368140935897827
iteration: 31400, loss: 1.605088710784912
iteration: 31450, loss: 1.2462071180343628
iteration: 31500, loss: 1.6333949565887451
iteration: 31550, loss: 1.2834256887435913
iteration: 31600, loss: 1.0781790018081665
iteration: 31650, loss: 1.419181227684021
iteration: 31700, loss: 1.1785732507705688
epoch 23, loss: 1.6319979000001328
epoch 24
iteration: 31750, loss: 1.0354199409484863
iteration: 31800, loss: 1.363104224205017
iteration: 31850, loss: 1.6632661819458008
iteration: 31900, loss: 1.586089849472046
iteration: 31950, loss: 1.579792857170105
iteration: 32000, loss: 2.0604984760284424
iteration: 32050, loss: 2.0071418285369873
iteration: 32100, loss: 1.3495674133300781
iteration: 32150, loss: 1.5883618593215942
iteration: 32200, loss: 1.7996760606765747
iteration: 32250, loss: 1.8322670459747314
iteration: 32300, loss: 1.213613748550415
iteration: 32350, loss: 1.5126389265060425
iteration: 32400, loss: 1.5312267541885376
iteration: 32450, loss: 1.7416809797286987
iteration: 32500, loss: 1.6289442777633667
iteration: 32550, loss: 2.0202877521514893
iteration: 32600, loss: 1.5244871377944946
iteration: 32650, loss: 1.5248486995697021
iteration: 32700, loss: 1.463862657546997
iteration: 32750, loss: 1.7113686800003052
iteration: 32800, loss: 1.2342523336410522
iteration: 32850, loss: 1.7640267610549927
iteration: 32900, loss: 1.719130277633667
iteration: 32950, loss: 1.8224107027053833
iteration: 33000, loss: 2.220263719558716
epoch 24, loss: 1.6270918662974376
epoch 25
iteration: 33050, loss: 1.9057502746582031
iteration: 33100, loss: 1.8047457933425903
iteration: 33150, loss: 2.3427562713623047
iteration: 33200, loss: 1.367753267288208
iteration: 33250, loss: 1.43255615234375
iteration: 33300, loss: 1.3953121900558472
iteration: 33350, loss: 1.1836812496185303
iteration: 33400, loss: 1.7607320547103882
iteration: 33450, loss: 1.7214100360870361
iteration: 33500, loss: 2.266105890274048
iteration: 33550, loss: 1.434312105178833
iteration: 33600, loss: 1.6370387077331543
iteration: 33650, loss: 1.7596498727798462
iteration: 33700, loss: 1.4757225513458252
iteration: 33750, loss: 1.4213154315948486
iteration: 33800, loss: 1.7777310609817505
iteration: 33850, loss: 1.7877508401870728
iteration: 33900, loss: 1.8051632642745972
iteration: 33950, loss: 1.3546103239059448
iteration: 34000, loss: 1.6185225248336792
iteration: 34050, loss: 1.865371823310852
iteration: 34100, loss: 1.6465439796447754
iteration: 34150, loss: 1.5046324729919434
iteration: 34200, loss: 1.3812503814697266
iteration: 34250, loss: 1.778149962425232
iteration: 34300, loss: 1.090843915939331
epoch 25, loss: 1.623640291399852
epoch 26
iteration: 34350, loss: 1.6419453620910645
iteration: 34400, loss: 1.5117743015289307
iteration: 34450, loss: 1.4565309286117554
iteration: 34500, loss: 1.4699417352676392
iteration: 34550, loss: 1.458374261856079
iteration: 34600, loss: 1.220554232597351
iteration: 34650, loss: 2.3282546997070312
iteration: 34700, loss: 2.0349650382995605
iteration: 34750, loss: 1.711898922920227
iteration: 34800, loss: 2.009911060333252
iteration: 34850, loss: 1.3906892538070679
iteration: 34900, loss: 1.3381145000457764
iteration: 34950, loss: 1.6493141651153564
iteration: 35000, loss: 1.9885469675064087
iteration: 35050, loss: 1.9156583547592163
iteration: 35100, loss: 1.4257705211639404
iteration: 35150, loss: 1.332809567451477
iteration: 35200, loss: 2.0155200958251953
iteration: 35250, loss: 1.5684980154037476
iteration: 35300, loss: 1.776337742805481
iteration: 35350, loss: 1.408967137336731
iteration: 35400, loss: 1.1899203062057495
iteration: 35450, loss: 1.9538203477859497
iteration: 35500, loss: 1.7183536291122437
iteration: 35550, loss: 1.437679648399353
iteration: 35600, loss: 1.298336386680603
iteration: 35650, loss: 1.382226586341858
epoch 26, loss: 1.6120411911209236
epoch 27
iteration: 35700, loss: 1.6041004657745361
iteration: 35750, loss: 1.5754753351211548
iteration: 35800, loss: 1.4603835344314575
iteration: 35850, loss: 1.6388803720474243
iteration: 35900, loss: 1.7226935625076294
iteration: 35950, loss: 1.4499175548553467
iteration: 36000, loss: 1.6392933130264282
iteration: 36050, loss: 1.6227673292160034
iteration: 36100, loss: 1.4010571241378784
iteration: 36150, loss: 1.513738989830017
iteration: 36200, loss: 1.3620295524597168
iteration: 36250, loss: 2.0576701164245605
iteration: 36300, loss: 1.3414682149887085
iteration: 36350, loss: 1.7649297714233398
iteration: 36400, loss: 2.219517707824707
iteration: 36450, loss: 1.5588397979736328
iteration: 36500, loss: 1.7528295516967773
iteration: 36550, loss: 1.5844228267669678
iteration: 36600, loss: 1.5000144243240356
iteration: 36650, loss: 1.3840774297714233
iteration: 36700, loss: 1.4989569187164307
iteration: 36750, loss: 1.3434020280838013
iteration: 36800, loss: 1.395028829574585
iteration: 36850, loss: 1.6913057565689087
iteration: 36900, loss: 1.3955953121185303
iteration: 36950, loss: 1.6516774892807007
epoch 27, loss: 1.5980946054972898
epoch 28
iteration: 37000, loss: 1.6347399950027466
iteration: 37050, loss: 1.4263663291931152
iteration: 37100, loss: 1.4726591110229492
iteration: 37150, loss: 1.254148244857788
iteration: 37200, loss: 1.575717806816101
iteration: 37250, loss: 1.2396677732467651
iteration: 37300, loss: 1.1339468955993652
iteration: 37350, loss: 1.4597734212875366
iteration: 37400, loss: 1.8568494319915771
iteration: 37450, loss: 1.472632884979248
iteration: 37500, loss: 1.428120493888855
iteration: 37550, loss: 1.2427575588226318
iteration: 37600, loss: 1.3852165937423706
iteration: 37650, loss: 1.2113404273986816
iteration: 37700, loss: 1.761289119720459
iteration: 37750, loss: 1.7436444759368896
iteration: 37800, loss: 1.2232282161712646
iteration: 37850, loss: 1.6529842615127563
iteration: 37900, loss: 1.6019994020462036
iteration: 37950, loss: 1.8955752849578857
iteration: 38000, loss: 1.5300109386444092
iteration: 38050, loss: 1.4543366432189941
iteration: 38100, loss: 1.652258276939392
iteration: 38150, loss: 1.270682692527771
iteration: 38200, loss: 1.1256992816925049
iteration: 38250, loss: 1.632743000984192
iteration: 38300, loss: 1.7736438512802124
epoch 28, loss: 1.594904547811344
epoch 29
iteration: 38350, loss: 1.8739527463912964
iteration: 38400, loss: 1.7398788928985596
iteration: 38450, loss: 1.5597567558288574
iteration: 38500, loss: 1.4600015878677368
iteration: 38550, loss: 1.8382554054260254
iteration: 38600, loss: 1.5654795169830322
iteration: 38650, loss: 1.9593652486801147
iteration: 38700, loss: 1.5349551439285278
iteration: 38750, loss: 1.853456974029541
iteration: 38800, loss: 1.540894865989685
iteration: 38850, loss: 1.3772310018539429
iteration: 38900, loss: 1.2859433889389038
iteration: 38950, loss: 1.2160780429840088
iteration: 39000, loss: 1.691631555557251
iteration: 39050, loss: 1.7540472745895386
iteration: 39100, loss: 1.8006927967071533
iteration: 39150, loss: 1.373164415359497
iteration: 39200, loss: 1.782184362411499
iteration: 39250, loss: 1.8482027053833008
iteration: 39300, loss: 1.1378639936447144
iteration: 39350, loss: 1.6369702816009521
iteration: 39400, loss: 1.7216609716415405
iteration: 39450, loss: 1.2098745107650757
iteration: 39500, loss: 1.125518560409546
iteration: 39550, loss: 1.2516604661941528
iteration: 39600, loss: 1.4346399307250977
epoch 29, loss: 1.5915247251768663
epoch 30
iteration: 39650, loss: 1.2633235454559326
iteration: 39700, loss: 1.6195670366287231
iteration: 39750, loss: 1.3394979238510132
iteration: 39800, loss: 1.493332028388977
iteration: 39850, loss: 1.3243571519851685
iteration: 39900, loss: 1.689438819885254
iteration: 39950, loss: 1.3287557363510132
iteration: 40000, loss: 1.742470622062683
iteration: 40050, loss: 1.6551928520202637
iteration: 40100, loss: 1.5372918844223022
iteration: 40150, loss: 1.47092604637146
iteration: 40200, loss: 1.4593169689178467
iteration: 40250, loss: 1.4154999256134033
iteration: 40300, loss: 2.095332145690918
iteration: 40350, loss: 1.5000554323196411
iteration: 40400, loss: 1.379281759262085
iteration: 40450, loss: 1.675436019897461
iteration: 40500, loss: 1.3184216022491455
iteration: 40550, loss: 1.0624388456344604
iteration: 40600, loss: 1.2903777360916138
iteration: 40650, loss: 1.589653491973877
iteration: 40700, loss: 1.5337536334991455
iteration: 40750, loss: 1.7329926490783691
iteration: 40800, loss: 1.4002500772476196
iteration: 40850, loss: 1.6794406175613403
iteration: 40900, loss: 1.4545429944992065
iteration: 40950, loss: 1.9372483491897583
epoch 30, loss: 1.5747534671141048
epoch 31
iteration: 41000, loss: 1.6496920585632324
iteration: 41050, loss: 1.3827683925628662
iteration: 41100, loss: 1.1313908100128174
iteration: 41150, loss: 2.0167481899261475
iteration: 41200, loss: 1.1862298250198364
iteration: 41250, loss: 1.6932134628295898
iteration: 41300, loss: 1.695826768875122
iteration: 41350, loss: 1.562522053718567
iteration: 41400, loss: 1.6711697578430176
iteration: 41450, loss: 1.5185884237289429
iteration: 41500, loss: 1.8053479194641113
iteration: 41550, loss: 1.685634970664978
iteration: 41600, loss: 1.7726794481277466
iteration: 41650, loss: 1.1742347478866577
iteration: 41700, loss: 1.655551791191101
iteration: 41750, loss: 1.1497745513916016
iteration: 41800, loss: 1.2446753978729248
iteration: 41850, loss: 1.1038782596588135
iteration: 41900, loss: 1.7816991806030273
iteration: 41950, loss: 1.791897177696228
iteration: 42000, loss: 1.5628589391708374
iteration: 42050, loss: 1.1426749229431152
iteration: 42100, loss: 1.5914524793624878
iteration: 42150, loss: 1.8214725255966187
iteration: 42200, loss: 1.6329604387283325
iteration: 42250, loss: 1.798611044883728
epoch 31, loss: 1.5803640740483915
epoch 32
iteration: 42300, loss: 1.5067037343978882
iteration: 42350, loss: 1.163449764251709
iteration: 42400, loss: 1.3448649644851685
iteration: 42450, loss: 1.5762616395950317
iteration: 42500, loss: 1.5452183485031128
iteration: 42550, loss: 1.7233279943466187
iteration: 42600, loss: 1.663014531135559
iteration: 42650, loss: 1.3900007009506226
iteration: 42700, loss: 1.4614490270614624
iteration: 42750, loss: 2.3093786239624023
iteration: 42800, loss: 1.0877940654754639
iteration: 42850, loss: 2.2429068088531494
iteration: 42900, loss: 1.502315878868103
iteration: 42950, loss: 1.2254146337509155
iteration: 43000, loss: 1.7858957052230835
iteration: 43050, loss: 1.1094608306884766
iteration: 43100, loss: 1.5414893627166748
iteration: 43150, loss: 1.5814849138259888
iteration: 43200, loss: 1.423609972000122
iteration: 43250, loss: 1.625029444694519
iteration: 43300, loss: 1.6473265886306763
iteration: 43350, loss: 1.5862398147583008
iteration: 43400, loss: 1.3886263370513916
iteration: 43450, loss: 1.9090148210525513
iteration: 43500, loss: 1.2016342878341675
iteration: 43550, loss: 1.4163473844528198
epoch 32, loss: 1.575749533201234
epoch 33
iteration: 43600, loss: 2.1996402740478516
iteration: 43650, loss: 1.3654993772506714
iteration: 43700, loss: 2.698035717010498
iteration: 43750, loss: 1.304927110671997
iteration: 43800, loss: 1.850114345550537
iteration: 43850, loss: 1.4482364654541016
iteration: 43900, loss: 1.6241081953048706
iteration: 43950, loss: 1.6473032236099243
iteration: 44000, loss: 1.6400346755981445
iteration: 44050, loss: 1.2962555885314941
iteration: 44100, loss: 1.4449337720870972
iteration: 44150, loss: 1.6274734735488892
iteration: 44200, loss: 1.0975298881530762
iteration: 44250, loss: 1.317606806755066
iteration: 44300, loss: 1.8342397212982178
iteration: 44350, loss: 1.3355668783187866
iteration: 44400, loss: 1.1265991926193237
iteration: 44450, loss: 1.4610236883163452
iteration: 44500, loss: 1.723665475845337
iteration: 44550, loss: 1.4126310348510742
iteration: 44600, loss: 1.4385967254638672
iteration: 44650, loss: 1.2923660278320312
iteration: 44700, loss: 1.2160271406173706
iteration: 44750, loss: 1.2085356712341309
iteration: 44800, loss: 1.543540120124817
iteration: 44850, loss: 1.711025595664978
iteration: 44900, loss: 1.3565787076950073
epoch 33, loss: 1.5685278166208836
epoch 34
iteration: 44950, loss: 2.4311907291412354
iteration: 45000, loss: 1.510017991065979
iteration: 45050, loss: 1.4157322645187378
iteration: 45100, loss: 2.3803112506866455
iteration: 45150, loss: 1.3791356086730957
iteration: 45200, loss: 1.855567455291748
iteration: 45250, loss: 1.633396029472351
iteration: 45300, loss: 1.3649381399154663
iteration: 45350, loss: 1.48821222782135
iteration: 45400, loss: 1.5971002578735352
iteration: 45450, loss: 1.851298451423645
iteration: 45500, loss: 1.498673677444458
iteration: 45550, loss: 1.5766316652297974
iteration: 45600, loss: 1.3656249046325684
iteration: 45650, loss: 1.4651755094528198
iteration: 45700, loss: 1.561976671218872
iteration: 45750, loss: 1.445508360862732
iteration: 45800, loss: 1.502846598625183
iteration: 45850, loss: 1.8013213872909546
iteration: 45900, loss: 1.273659110069275
iteration: 45950, loss: 1.121950626373291
iteration: 46000, loss: 1.4925813674926758
iteration: 46050, loss: 1.727156400680542
iteration: 46100, loss: 1.525691270828247
iteration: 46150, loss: 1.3236100673675537
iteration: 46200, loss: 1.1555259227752686
epoch 34, loss: 1.5614095668467916
epoch 35
iteration: 46250, loss: 1.2095717191696167
iteration: 46300, loss: 1.6094379425048828
iteration: 46350, loss: 1.7715662717819214
iteration: 46400, loss: 1.4981434345245361
iteration: 46450, loss: 1.7039353847503662
iteration: 46500, loss: 1.5015496015548706
iteration: 46550, loss: 1.3174430131912231
iteration: 46600, loss: 1.846018671989441
iteration: 46650, loss: 1.504830002784729
iteration: 46700, loss: 1.618250846862793
iteration: 46750, loss: 1.5239250659942627
iteration: 46800, loss: 1.442846655845642
iteration: 46850, loss: 1.27371346950531
iteration: 46900, loss: 1.3946460485458374
iteration: 46950, loss: 1.2638452053070068
iteration: 47000, loss: 1.520823359489441
iteration: 47050, loss: 1.0921794176101685
iteration: 47100, loss: 1.8681377172470093
iteration: 47150, loss: 0.9994953870773315
iteration: 47200, loss: 1.7097994089126587
iteration: 47250, loss: 1.3563098907470703
iteration: 47300, loss: 1.2799146175384521
iteration: 47350, loss: 1.167559027671814
iteration: 47400, loss: 1.4396419525146484
iteration: 47450, loss: 1.5213755369186401
iteration: 47500, loss: 1.714363932609558
iteration: 47550, loss: 1.8345876932144165
epoch 35, loss: 1.5571357519534137
epoch 36
iteration: 47600, loss: 1.291786789894104
iteration: 47650, loss: 1.5550960302352905
iteration: 47700, loss: 1.6450434923171997
iteration: 47750, loss: 1.2647321224212646
iteration: 47800, loss: 1.2403044700622559
iteration: 47850, loss: 1.7182888984680176
iteration: 47900, loss: 1.2959785461425781
iteration: 47950, loss: 1.5865026712417603
iteration: 48000, loss: 1.8935500383377075
iteration: 48050, loss: 2.1298763751983643
iteration: 48100, loss: 1.893700122833252
iteration: 48150, loss: 1.3254427909851074
iteration: 48200, loss: 1.601454257965088
iteration: 48250, loss: 1.5849202871322632
iteration: 48300, loss: 1.473480224609375
iteration: 48350, loss: 1.3352699279785156
iteration: 48400, loss: 1.2481908798217773
iteration: 48450, loss: 1.1989648342132568
iteration: 48500, loss: 1.5080732107162476
iteration: 48550, loss: 1.4960613250732422
iteration: 48600, loss: 2.1302223205566406
iteration: 48650, loss: 1.4783766269683838
iteration: 48700, loss: 1.155014157295227
iteration: 48750, loss: 1.6933878660202026
iteration: 48800, loss: 1.4373513460159302
iteration: 48850, loss: 1.8988829851150513
epoch 36, loss: 1.5534832960271339
epoch 37
iteration: 48900, loss: 1.6692111492156982
iteration: 48950, loss: 1.6864887475967407
iteration: 49000, loss: 1.3943634033203125
iteration: 49050, loss: 2.4295151233673096
iteration: 49100, loss: 1.8094596862792969
iteration: 49150, loss: 1.907149314880371
iteration: 49200, loss: 1.4811538457870483
iteration: 49250, loss: 1.8473814725875854
iteration: 49300, loss: 1.6106147766113281
iteration: 49350, loss: 1.5719047784805298
iteration: 49400, loss: 1.9566659927368164
iteration: 49450, loss: 1.3123096227645874
iteration: 49500, loss: 2.1072983741760254
iteration: 49550, loss: 1.447246789932251
iteration: 49600, loss: 1.6220266819000244
iteration: 49650, loss: 2.10005521774292
iteration: 49700, loss: 1.641351342201233
iteration: 49750, loss: 1.4540551900863647
iteration: 49800, loss: 1.6435291767120361
iteration: 49850, loss: 2.355524778366089
iteration: 49900, loss: 1.6383180618286133
iteration: 49950, loss: 1.35599684715271
iteration: 50000, loss: 1.096921443939209
iteration: 50050, loss: 1.4402129650115967
iteration: 50100, loss: 1.702488660812378
iteration: 50150, loss: 1.5257076025009155
epoch 37, loss: 1.551534226218145
epoch 38
iteration: 50200, loss: 1.1430881023406982
iteration: 50250, loss: 2.4575679302215576
iteration: 50300, loss: 1.3261507749557495
iteration: 50350, loss: 1.478236436843872
iteration: 50400, loss: 1.5805336236953735
iteration: 50450, loss: 1.3814246654510498
iteration: 50500, loss: 1.4656174182891846
iteration: 50550, loss: 1.3669077157974243
iteration: 50600, loss: 1.2836945056915283
iteration: 50650, loss: 1.9083127975463867
iteration: 50700, loss: 1.5311801433563232
iteration: 50750, loss: 2.3645272254943848
iteration: 50800, loss: 1.1519887447357178
iteration: 50850, loss: 1.9993032217025757
iteration: 50900, loss: 1.9602173566818237
iteration: 50950, loss: 1.606934905052185
iteration: 51000, loss: 1.467566728591919
iteration: 51050, loss: 1.4426935911178589
iteration: 51100, loss: 1.336866855621338
iteration: 51150, loss: 1.8396828174591064
iteration: 51200, loss: 1.5325396060943604
iteration: 51250, loss: 1.3315422534942627
iteration: 51300, loss: 1.3257060050964355
iteration: 51350, loss: 1.772203803062439
iteration: 51400, loss: 1.2323468923568726
iteration: 51450, loss: 1.5671268701553345
iteration: 51500, loss: 1.13566255569458
epoch 38, loss: 1.5420233097184686
epoch 39
iteration: 51550, loss: 2.5339810848236084
iteration: 51600, loss: 1.7254676818847656
iteration: 51650, loss: 1.4379078149795532
iteration: 51700, loss: 1.6769481897354126
iteration: 51750, loss: 1.3391929864883423
iteration: 51800, loss: 1.490416407585144
iteration: 51850, loss: 1.2412974834442139
iteration: 51900, loss: 1.5350263118743896
iteration: 51950, loss: 1.6564096212387085
iteration: 52000, loss: 1.4740040302276611
iteration: 52050, loss: 1.4589800834655762
iteration: 52100, loss: 2.287200927734375
iteration: 52150, loss: 1.4813889265060425
iteration: 52200, loss: 1.421371340751648
iteration: 52250, loss: 1.1834595203399658
iteration: 52300, loss: 1.6668434143066406
iteration: 52350, loss: 1.1196750402450562
iteration: 52400, loss: 1.6973350048065186
iteration: 52450, loss: 1.2675217390060425
iteration: 52500, loss: 1.7912760972976685
iteration: 52550, loss: 1.9400997161865234
iteration: 52600, loss: 1.6544619798660278
iteration: 52650, loss: 1.650050163269043
iteration: 52700, loss: 1.5761460065841675
iteration: 52750, loss: 1.6447094678878784
iteration: 52800, loss: 1.9760688543319702
epoch 39, loss: 1.5378986870667342
epoch 40
iteration: 52850, loss: 1.8351041078567505
iteration: 52900, loss: 1.4493852853775024
iteration: 52950, loss: 1.6442221403121948
iteration: 53000, loss: 1.6680402755737305
iteration: 53050, loss: 1.172167181968689
iteration: 53100, loss: 1.732049584388733
iteration: 53150, loss: 1.2320321798324585
iteration: 53200, loss: 2.056591510772705
iteration: 53250, loss: 1.2256717681884766
iteration: 53300, loss: 1.1759989261627197
iteration: 53350, loss: 1.333442211151123
iteration: 53400, loss: 1.3296003341674805
iteration: 53450, loss: 1.5674467086791992
iteration: 53500, loss: 1.5981128215789795
iteration: 53550, loss: 1.5118046998977661
iteration: 53600, loss: 1.3086168766021729
iteration: 53650, loss: 2.9368975162506104
iteration: 53700, loss: 1.19281005859375
iteration: 53750, loss: 1.4586411714553833
iteration: 53800, loss: 1.651550531387329
iteration: 53850, loss: 1.5181999206542969
iteration: 53900, loss: 1.7748477458953857
iteration: 53950, loss: 2.3422484397888184
iteration: 54000, loss: 2.0415666103363037
iteration: 54050, loss: 1.5477045774459839
iteration: 54100, loss: 1.7958950996398926
iteration: 54150, loss: 1.5451457500457764
epoch 40, loss: 1.5367693437307424
epoch 41
iteration: 54200, loss: 1.5976696014404297
iteration: 54250, loss: 1.551383376121521
iteration: 54300, loss: 1.5038598775863647
iteration: 54350, loss: 1.5629916191101074
iteration: 54400, loss: 1.3811367750167847
iteration: 54450, loss: 1.190057396888733
iteration: 54500, loss: 1.171114206314087
iteration: 54550, loss: 1.902735710144043
iteration: 54600, loss: 1.8656426668167114
iteration: 54650, loss: 1.804184913635254
iteration: 54700, loss: 1.6750603914260864
iteration: 54750, loss: 1.4647917747497559
iteration: 54800, loss: 1.5545358657836914
iteration: 54850, loss: 1.6150671243667603
iteration: 54900, loss: 2.173415422439575
iteration: 54950, loss: 1.5800485610961914
iteration: 55000, loss: 1.780794620513916
iteration: 55050, loss: 1.5682885646820068
iteration: 55100, loss: 1.6901010274887085
iteration: 55150, loss: 2.4260928630828857
iteration: 55200, loss: 1.56016206741333
iteration: 55250, loss: 1.4359127283096313
iteration: 55300, loss: 1.0554661750793457
iteration: 55350, loss: 1.2799099683761597
iteration: 55400, loss: 1.8613344430923462
iteration: 55450, loss: 1.4673409461975098
epoch 41, loss: 1.5218452176623674
epoch 42
iteration: 55500, loss: 1.9881402254104614
iteration: 55550, loss: 1.9868614673614502
iteration: 55600, loss: 1.3659173250198364
iteration: 55650, loss: 1.517765760421753
iteration: 55700, loss: 1.3733960390090942
iteration: 55750, loss: 1.4140251874923706
iteration: 55800, loss: 1.4584702253341675
iteration: 55850, loss: 1.7131649255752563
iteration: 55900, loss: 1.404647946357727
iteration: 55950, loss: 1.686160683631897
iteration: 56000, loss: 1.7129729986190796
iteration: 56050, loss: 1.8496509790420532
iteration: 56100, loss: 1.7454663515090942
iteration: 56150, loss: 1.3318482637405396
iteration: 56200, loss: 1.4918500185012817
iteration: 56250, loss: 1.7323200702667236
iteration: 56300, loss: 2.074275255203247
iteration: 56350, loss: 1.4735078811645508
iteration: 56400, loss: 1.9031708240509033
iteration: 56450, loss: 1.2534922361373901
iteration: 56500, loss: 1.313265323638916
iteration: 56550, loss: 1.533318042755127
iteration: 56600, loss: 1.3224881887435913
iteration: 56650, loss: 1.4932860136032104
iteration: 56700, loss: 1.4611395597457886
iteration: 56750, loss: 1.0415380001068115
iteration: 56800, loss: 1.2127071619033813
epoch 42, loss: 1.5166107766901196
epoch 43
iteration: 56850, loss: 1.4447277784347534
iteration: 56900, loss: 1.4506622552871704
iteration: 56950, loss: 1.2718521356582642
iteration: 57000, loss: 1.4652118682861328
iteration: 57050, loss: 1.4634549617767334
iteration: 57100, loss: 1.729108452796936
iteration: 57150, loss: 1.6029994487762451
iteration: 57200, loss: 1.6604974269866943
iteration: 57250, loss: 1.6269639730453491
iteration: 57300, loss: 1.4168959856033325
iteration: 57350, loss: 1.2183172702789307
iteration: 57400, loss: 1.8356858491897583
iteration: 57450, loss: 1.336485743522644
iteration: 57500, loss: 1.4355506896972656
iteration: 57550, loss: 1.523002028465271
iteration: 57600, loss: 1.375283122062683
iteration: 57650, loss: 1.7257908582687378
iteration: 57700, loss: 1.3182928562164307
iteration: 57750, loss: 1.7706021070480347
iteration: 57800, loss: 1.018062710762024
iteration: 57850, loss: 1.430954098701477
iteration: 57900, loss: 1.332471251487732
iteration: 57950, loss: 0.9215607047080994
iteration: 58000, loss: 1.2729196548461914
iteration: 58050, loss: 1.9666911363601685
iteration: 58100, loss: 1.5357980728149414
epoch 43, loss: 1.5237442602159397
epoch 44
iteration: 58150, loss: 1.3667024374008179
iteration: 58200, loss: 2.2730391025543213
iteration: 58250, loss: 1.4789140224456787
iteration: 58300, loss: 1.795441746711731
iteration: 58350, loss: 1.7093757390975952
iteration: 58400, loss: 1.697454810142517
iteration: 58450, loss: 1.2926658391952515
iteration: 58500, loss: 1.5620810985565186
iteration: 58550, loss: 1.5738372802734375
iteration: 58600, loss: 1.5063813924789429
iteration: 58650, loss: 1.3529175519943237
iteration: 58700, loss: 1.3604470491409302
iteration: 58750, loss: 1.1967142820358276
iteration: 58800, loss: 1.6430543661117554
iteration: 58850, loss: 1.5636931657791138
iteration: 58900, loss: 1.1788221597671509
iteration: 58950, loss: 1.932849407196045
iteration: 59000, loss: 1.2556846141815186
iteration: 59050, loss: 1.4357106685638428
iteration: 59100, loss: 1.357627511024475
iteration: 59150, loss: 1.2223752737045288
iteration: 59200, loss: 1.415018081665039
iteration: 59250, loss: 1.3682434558868408
iteration: 59300, loss: 1.4323043823242188
iteration: 59350, loss: 1.7017223834991455
iteration: 59400, loss: 1.7775837182998657
epoch 44, loss: 1.5089568011808079
epoch 45
iteration: 59450, loss: 1.5468350648880005
iteration: 59500, loss: 1.051721215248108
iteration: 59550, loss: 1.4169291257858276
iteration: 59600, loss: 1.2166316509246826
iteration: 59650, loss: 1.6361116170883179
iteration: 59700, loss: 1.3999336957931519
iteration: 59750, loss: 1.6710244417190552
iteration: 59800, loss: 1.2313690185546875
iteration: 59850, loss: 1.5544477701187134
iteration: 59900, loss: 1.7300083637237549
iteration: 59950, loss: 1.1804745197296143
iteration: 60000, loss: 1.9732259511947632
iteration: 60050, loss: 1.7745128870010376
iteration: 60100, loss: 1.4524999856948853
iteration: 60150, loss: 1.416631817817688
iteration: 60200, loss: 1.496618390083313
iteration: 60250, loss: 1.1396242380142212
iteration: 60300, loss: 1.6140427589416504
iteration: 60350, loss: 1.1351549625396729
iteration: 60400, loss: 1.5099284648895264
iteration: 60450, loss: 1.4996262788772583
iteration: 60500, loss: 1.4437735080718994
iteration: 60550, loss: 1.6434756517410278
iteration: 60600, loss: 1.314753532409668
iteration: 60650, loss: 1.3673378229141235
iteration: 60700, loss: 1.869983434677124
iteration: 60750, loss: 1.428296685218811
epoch 45, loss: 1.507587246006124
epoch 46
iteration: 60800, loss: 1.3655074834823608
iteration: 60850, loss: 1.5237703323364258
iteration: 60900, loss: 1.4359790086746216
iteration: 60950, loss: 1.8800888061523438
iteration: 61000, loss: 1.705475091934204
iteration: 61050, loss: 1.355165719985962
iteration: 61100, loss: 1.505507230758667
iteration: 61150, loss: 1.0528334379196167
iteration: 61200, loss: 1.3169538974761963
iteration: 61250, loss: 1.7656688690185547
iteration: 61300, loss: 1.7775533199310303
iteration: 61350, loss: 1.1988170146942139
iteration: 61400, loss: 1.5790587663650513
iteration: 61450, loss: 1.1929855346679688
iteration: 61500, loss: 1.676542043685913
iteration: 61550, loss: 1.4356569051742554
iteration: 61600, loss: 1.2204676866531372
iteration: 61650, loss: 1.2257795333862305
iteration: 61700, loss: 1.4601187705993652
iteration: 61750, loss: 1.1085158586502075
iteration: 61800, loss: 1.8115118741989136
iteration: 61850, loss: 1.4630874395370483
iteration: 61900, loss: 1.4543044567108154
iteration: 61950, loss: 1.1421600580215454
iteration: 62000, loss: 1.457228183746338
iteration: 62050, loss: 1.113097071647644
epoch 46, loss: 1.4966785589252425
epoch 47
iteration: 62100, loss: 2.142591953277588
iteration: 62150, loss: 1.31264328956604
iteration: 62200, loss: 1.5348548889160156
iteration: 62250, loss: 1.7854634523391724
iteration: 62300, loss: 1.3234840631484985
iteration: 62350, loss: 1.3850041627883911
iteration: 62400, loss: 1.825195550918579
iteration: 62450, loss: 1.5090765953063965
iteration: 62500, loss: 2.0236308574676514
iteration: 62550, loss: 1.6462064981460571
iteration: 62600, loss: 1.6267496347427368
iteration: 62650, loss: 1.094774603843689
iteration: 62700, loss: 1.5190842151641846
iteration: 62750, loss: 1.336761236190796
iteration: 62800, loss: 1.3599690198898315
iteration: 62850, loss: 1.241834282875061
iteration: 62900, loss: 1.3472599983215332
iteration: 62950, loss: 1.467821478843689
iteration: 63000, loss: 2.0080718994140625
iteration: 63050, loss: 1.4060670137405396
iteration: 63100, loss: 1.1495320796966553
iteration: 63150, loss: 1.4644283056259155
iteration: 63200, loss: 1.5090909004211426
iteration: 63250, loss: 1.255794644355774
iteration: 63300, loss: 1.1975195407867432
iteration: 63350, loss: 1.617885708808899
iteration: 63400, loss: 1.4174442291259766
epoch 47, loss: 1.500366594347056
epoch 48
iteration: 63450, loss: 1.4113271236419678
iteration: 63500, loss: 1.4659289121627808
iteration: 63550, loss: 1.7087451219558716
iteration: 63600, loss: 1.0615100860595703
iteration: 63650, loss: 1.9220011234283447
iteration: 63700, loss: 1.2796229124069214
iteration: 63750, loss: 1.9422167539596558
iteration: 63800, loss: 1.6169415712356567
iteration: 63850, loss: 1.4802870750427246
iteration: 63900, loss: 1.5261482000350952
iteration: 63950, loss: 1.3772584199905396
iteration: 64000, loss: 1.4951727390289307
iteration: 64050, loss: 1.8132503032684326
iteration: 64100, loss: 1.5692143440246582
iteration: 64150, loss: 1.8176474571228027
iteration: 64200, loss: 1.4258941411972046
iteration: 64250, loss: 1.9446158409118652
iteration: 64300, loss: 1.792251706123352
iteration: 64350, loss: 1.3245240449905396
iteration: 64400, loss: 1.6498548984527588
iteration: 64450, loss: 1.5766710042953491
iteration: 64500, loss: 1.4931325912475586
iteration: 64550, loss: 0.8795429468154907
iteration: 64600, loss: 1.243200421333313
iteration: 64650, loss: 1.499282717704773
iteration: 64700, loss: 1.5658509731292725
epoch 48, loss: 1.500156126455417
epoch 49
iteration: 64750, loss: 1.162671446800232
iteration: 64800, loss: 1.3382017612457275
iteration: 64850, loss: 1.8160345554351807
iteration: 64900, loss: 1.4095946550369263
iteration: 64950, loss: 1.1343954801559448
iteration: 65000, loss: 1.269530177116394
iteration: 65050, loss: 1.7077125310897827
iteration: 65100, loss: 1.1669834852218628
iteration: 65150, loss: 1.6784744262695312
iteration: 65200, loss: 1.2818717956542969
iteration: 65250, loss: 1.298500657081604
iteration: 65300, loss: 1.7211661338806152
iteration: 65350, loss: 1.4539324045181274
iteration: 65400, loss: 1.4459480047225952
iteration: 65450, loss: 1.2857736349105835
iteration: 65500, loss: 1.5957109928131104
iteration: 65550, loss: 1.4603321552276611
iteration: 65600, loss: 0.8706347346305847
iteration: 65650, loss: 1.1902180910110474
iteration: 65700, loss: 1.7210698127746582
iteration: 65750, loss: 1.6365724802017212
iteration: 65800, loss: 1.9477916955947876
iteration: 65850, loss: 1.6001865863800049
iteration: 65900, loss: 1.6041817665100098
iteration: 65950, loss: 1.1739146709442139
iteration: 66000, loss: 1.7331433296203613
iteration: 66050, loss: 1.5884833335876465
epoch 49, loss: 1.494924070932105
epoch 50
iteration: 66100, loss: 0.9751747846603394
iteration: 66150, loss: 1.413586974143982
iteration: 66200, loss: 1.5703186988830566
iteration: 66250, loss: 1.5185567140579224
iteration: 66300, loss: 1.3405400514602661
iteration: 66350, loss: 1.6340012550354004
iteration: 66400, loss: 1.5424500703811646
iteration: 66450, loss: 1.2086116075515747
iteration: 66500, loss: 1.6559317111968994
iteration: 66550, loss: 1.2176302671432495
iteration: 66600, loss: 1.504955530166626
iteration: 66650, loss: 1.227997064590454
iteration: 66700, loss: 1.2846218347549438
iteration: 66750, loss: 1.228064775466919
iteration: 66800, loss: 1.470992922782898
iteration: 66850, loss: 1.7495577335357666
iteration: 66900, loss: 1.7681384086608887
iteration: 66950, loss: 1.2904677391052246
iteration: 67000, loss: 1.540020227432251
iteration: 67050, loss: 1.471623182296753
iteration: 67100, loss: 2.0357344150543213
iteration: 67150, loss: 1.8501940965652466
iteration: 67200, loss: 1.2733579874038696
iteration: 67250, loss: 1.145464539527893
iteration: 67300, loss: 1.5270417928695679
iteration: 67350, loss: 1.1222953796386719
epoch 50, loss: 1.4765949584903193
epoch 51
iteration: 67400, loss: 0.9846383333206177
iteration: 67450, loss: 1.3550829887390137
iteration: 67500, loss: 1.6093569993972778
iteration: 67550, loss: 1.5053809881210327
iteration: 67600, loss: 1.272742509841919
iteration: 67650, loss: 1.57399582862854
iteration: 67700, loss: 2.092947483062744
iteration: 67750, loss: 1.7029953002929688
iteration: 67800, loss: 1.6908169984817505
iteration: 67850, loss: 1.6321580410003662
iteration: 67900, loss: 1.3395916223526
iteration: 67950, loss: 2.0819671154022217
iteration: 68000, loss: 1.5042868852615356
iteration: 68050, loss: 1.4275567531585693
iteration: 68100, loss: 1.463018536567688
iteration: 68150, loss: 1.50473952293396
iteration: 68200, loss: 1.5653389692306519
iteration: 68250, loss: 1.506641149520874
iteration: 68300, loss: 1.1693955659866333
iteration: 68350, loss: 1.8510292768478394
iteration: 68400, loss: 1.1243345737457275
iteration: 68450, loss: 1.9628899097442627
iteration: 68500, loss: 1.6955312490463257
iteration: 68550, loss: 1.4555108547210693
iteration: 68600, loss: 1.5771490335464478
iteration: 68650, loss: 1.4852644205093384
epoch 51, loss: 1.4762733986835606
epoch 52
iteration: 68700, loss: 1.354385495185852
iteration: 68750, loss: 1.335128664970398
iteration: 68800, loss: 1.296776294708252
iteration: 68850, loss: 1.1206895112991333
iteration: 68900, loss: 1.7234642505645752
iteration: 68950, loss: 1.3763859272003174
iteration: 69000, loss: 1.9570553302764893
iteration: 69050, loss: 1.2800486087799072
iteration: 69100, loss: 1.7285233736038208
iteration: 69150, loss: 1.2322615385055542
iteration: 69200, loss: 1.2581239938735962
iteration: 69250, loss: 1.7360535860061646
iteration: 69300, loss: 1.4401748180389404
iteration: 69350, loss: 1.5562524795532227
iteration: 69400, loss: 1.22653067111969
iteration: 69450, loss: 1.180710792541504
iteration: 69500, loss: 1.5008883476257324
iteration: 69550, loss: 1.722802758216858
iteration: 69600, loss: 1.9345643520355225
iteration: 69650, loss: 1.616288661956787
iteration: 69700, loss: 1.6621942520141602
iteration: 69750, loss: 1.1219658851623535
iteration: 69800, loss: 1.955191969871521
iteration: 69850, loss: 1.46817147731781
iteration: 69900, loss: 1.5356299877166748
iteration: 69950, loss: 1.3959050178527832
iteration: 70000, loss: 1.554307222366333
epoch 52, loss: 1.471636356626238
epoch 53
iteration: 70050, loss: 1.981119990348816
iteration: 70100, loss: 1.2586451768875122
iteration: 70150, loss: 1.5635292530059814
iteration: 70200, loss: 1.6184512376785278
iteration: 70250, loss: 1.7127516269683838
iteration: 70300, loss: 1.5887128114700317
iteration: 70350, loss: 1.526919960975647
iteration: 70400, loss: 1.0680960416793823
iteration: 70450, loss: 1.3388569355010986
iteration: 70500, loss: 1.6541680097579956
iteration: 70550, loss: 1.4441970586776733
iteration: 70600, loss: 1.3376590013504028
iteration: 70650, loss: 1.3212074041366577
iteration: 70700, loss: 1.3228143453598022
iteration: 70750, loss: 1.3878018856048584
iteration: 70800, loss: 1.7139873504638672
iteration: 70850, loss: 1.303369164466858
iteration: 70900, loss: 1.4006202220916748
iteration: 70950, loss: 1.4723082780838013
iteration: 71000, loss: 1.317566156387329
iteration: 71050, loss: 1.8264182806015015
iteration: 71100, loss: 1.5698789358139038
iteration: 71150, loss: 1.5789613723754883
iteration: 71200, loss: 1.1036688089370728
iteration: 71250, loss: 1.9332048892974854
iteration: 71300, loss: 1.3850891590118408
epoch 53, loss: 1.4799390422925705
epoch 54
iteration: 71350, loss: 1.574340581893921
iteration: 71400, loss: 1.64651358127594
iteration: 71450, loss: 1.1762330532073975
iteration: 71500, loss: 1.249635934829712
iteration: 71550, loss: 1.1286249160766602
iteration: 71600, loss: 1.8478834629058838
iteration: 71650, loss: 1.0453940629959106
iteration: 71700, loss: 1.7232489585876465
iteration: 71750, loss: 1.4183639287948608
iteration: 71800, loss: 1.462478518486023
iteration: 71850, loss: 0.9636658430099487
iteration: 71900, loss: 1.3475130796432495
iteration: 71950, loss: 1.3820773363113403
iteration: 72000, loss: 1.462288737297058
iteration: 72050, loss: 1.925323486328125
iteration: 72100, loss: 1.2650954723358154
iteration: 72150, loss: 1.9522181749343872
iteration: 72200, loss: 1.3896291255950928
iteration: 72250, loss: 1.5663912296295166
iteration: 72300, loss: 1.6734079122543335
iteration: 72350, loss: 1.6059802770614624
iteration: 72400, loss: 1.2758623361587524
iteration: 72450, loss: 1.3164424896240234
iteration: 72500, loss: 2.4290952682495117
iteration: 72550, loss: 1.5264450311660767
iteration: 72600, loss: 1.0769871473312378
iteration: 72650, loss: 1.6680717468261719
epoch 54, loss: 1.467129911424534
epoch 55
iteration: 72700, loss: 1.610771656036377
iteration: 72750, loss: 1.3325892686843872
iteration: 72800, loss: 1.4617494344711304
iteration: 72850, loss: 1.8359125852584839
iteration: 72900, loss: 1.6854243278503418
iteration: 72950, loss: 1.5491540431976318
iteration: 73000, loss: 1.230554461479187
iteration: 73050, loss: 1.276208758354187
iteration: 73100, loss: 1.0293560028076172
iteration: 73150, loss: 1.155034065246582
iteration: 73200, loss: 2.316049814224243
iteration: 73250, loss: 1.1389583349227905
iteration: 73300, loss: 1.836936354637146
iteration: 73350, loss: 1.7187696695327759
iteration: 73400, loss: 1.205433964729309
iteration: 73450, loss: 1.649972677230835
iteration: 73500, loss: 1.4121594429016113
iteration: 73550, loss: 1.2821992635726929
iteration: 73600, loss: 1.5713087320327759
iteration: 73650, loss: 1.3963966369628906
iteration: 73700, loss: 1.3286606073379517
iteration: 73750, loss: 1.3842946290969849
iteration: 73800, loss: 1.6504524946212769
iteration: 73850, loss: 1.2821019887924194
iteration: 73900, loss: 1.5906383991241455
iteration: 73950, loss: 1.4123421907424927
epoch 55, loss: 1.4740320931545607
epoch 56
iteration: 74000, loss: 1.2022637128829956
iteration: 74050, loss: 1.088842749595642
iteration: 74100, loss: 1.2409340143203735
iteration: 74150, loss: 1.4776694774627686
iteration: 74200, loss: 1.6483335494995117
iteration: 74250, loss: 1.5795276165008545
iteration: 74300, loss: 1.3840879201889038
iteration: 74350, loss: 1.4616625308990479
iteration: 74400, loss: 1.8778637647628784
iteration: 74450, loss: 0.9682425260543823
iteration: 74500, loss: 1.2797859907150269
iteration: 74550, loss: 1.3979289531707764
iteration: 74600, loss: 1.1754004955291748
iteration: 74650, loss: 2.5425808429718018
iteration: 74700, loss: 1.2810561656951904
iteration: 74750, loss: 1.7827837467193604
iteration: 74800, loss: 1.7663618326187134
iteration: 74850, loss: 1.3927041292190552
iteration: 74900, loss: 1.7344862222671509
iteration: 74950, loss: 1.2930102348327637
iteration: 75000, loss: 2.117710828781128
iteration: 75050, loss: 1.1057449579238892
iteration: 75100, loss: 1.0958893299102783
iteration: 75150, loss: 1.279585838317871
iteration: 75200, loss: 2.231882333755493
iteration: 75250, loss: 1.253246545791626
epoch 56, loss: 1.4628557834516975
epoch 57
iteration: 75300, loss: 1.712198257446289
iteration: 75350, loss: 1.2541168928146362
iteration: 75400, loss: 1.4413219690322876
iteration: 75450, loss: 1.7565664052963257
iteration: 75500, loss: 1.799641489982605
iteration: 75550, loss: 1.4961278438568115
iteration: 75600, loss: 1.3091485500335693
iteration: 75650, loss: 1.567237377166748
iteration: 75700, loss: 1.3653594255447388
iteration: 75750, loss: 1.551260232925415
iteration: 75800, loss: 1.7033135890960693
iteration: 75850, loss: 1.5712965726852417
iteration: 75900, loss: 1.5315632820129395
iteration: 75950, loss: 1.0023669004440308
iteration: 76000, loss: 1.1088626384735107
iteration: 76050, loss: 1.9392352104187012
iteration: 76100, loss: 1.559151291847229
iteration: 76150, loss: 1.4205869436264038
iteration: 76200, loss: 1.8487980365753174
iteration: 76250, loss: 1.4236005544662476
iteration: 76300, loss: 1.3325976133346558
iteration: 76350, loss: 1.24209725856781
iteration: 76400, loss: 1.7761012315750122
iteration: 76450, loss: 1.269348382949829
iteration: 76500, loss: 1.5448049306869507
iteration: 76550, loss: 1.3552751541137695
iteration: 76600, loss: 2.328199625015259
epoch 57, loss: 1.462198725035423
epoch 58
iteration: 76650, loss: 1.4038333892822266
iteration: 76700, loss: 1.4261285066604614
iteration: 76750, loss: 1.220013976097107
iteration: 76800, loss: 0.9911656975746155
iteration: 76850, loss: 1.4145554304122925
iteration: 76900, loss: 1.6256215572357178
iteration: 76950, loss: 1.193129539489746
iteration: 77000, loss: 1.3941857814788818
iteration: 77050, loss: 1.129313588142395
iteration: 77100, loss: 1.491377830505371
iteration: 77150, loss: 1.5736501216888428
iteration: 77200, loss: 1.3381943702697754
iteration: 77250, loss: 1.0486804246902466
iteration: 77300, loss: 1.5538159608840942
iteration: 77350, loss: 1.1148015260696411
iteration: 77400, loss: 1.2721449136734009
iteration: 77450, loss: 1.3358538150787354
iteration: 77500, loss: 1.6286462545394897
iteration: 77550, loss: 1.379981279373169
iteration: 77600, loss: 1.3358232975006104
iteration: 77650, loss: 2.092102527618408
iteration: 77700, loss: 1.6928988695144653
iteration: 77750, loss: 1.6171199083328247
iteration: 77800, loss: 1.944193959236145
iteration: 77850, loss: 1.8028361797332764
iteration: 77900, loss: 1.1359269618988037
epoch 58, loss: 1.4620965088778435
epoch 59
iteration: 77950, loss: 1.3697489500045776
iteration: 78000, loss: 1.163978099822998
iteration: 78050, loss: 1.455228567123413
iteration: 78100, loss: 1.3455655574798584
iteration: 78150, loss: 1.611636757850647
iteration: 78200, loss: 1.679935097694397
iteration: 78250, loss: 1.2705057859420776
iteration: 78300, loss: 1.6865803003311157
iteration: 78350, loss: 1.1785695552825928
iteration: 78400, loss: 1.378137469291687
iteration: 78450, loss: 1.9575023651123047
iteration: 78500, loss: 1.2812695503234863
iteration: 78550, loss: 0.9060196280479431
iteration: 78600, loss: 1.3954260349273682
iteration: 78650, loss: 1.967538595199585
iteration: 78700, loss: 1.271345615386963
iteration: 78750, loss: 1.4207136631011963
iteration: 78800, loss: 1.4725078344345093
iteration: 78850, loss: 1.6616675853729248
iteration: 78900, loss: 1.4243375062942505
iteration: 78950, loss: 1.2444578409194946
iteration: 79000, loss: 1.0299452543258667
iteration: 79050, loss: 1.2230751514434814
iteration: 79100, loss: 1.3545081615447998
iteration: 79150, loss: 1.3822429180145264
iteration: 79200, loss: 1.661732792854309
iteration: 79250, loss: 1.5968607664108276
epoch 59, loss: 1.4537021990643433
epoch 60
iteration: 79300, loss: 1.6427851915359497
iteration: 79350, loss: 1.4583508968353271
iteration: 79400, loss: 1.340671181678772
iteration: 79450, loss: 1.5383517742156982
iteration: 79500, loss: 0.8716073036193848
iteration: 79550, loss: 1.3938044309616089
iteration: 79600, loss: 1.604922890663147
iteration: 79650, loss: 1.311000108718872
iteration: 79700, loss: 1.5402162075042725
iteration: 79750, loss: 1.5250166654586792
iteration: 79800, loss: 1.4757544994354248
iteration: 79850, loss: 1.8909832239151
iteration: 79900, loss: 1.519634485244751
iteration: 79950, loss: 1.6321907043457031
iteration: 80000, loss: 1.852424144744873
iteration: 80050, loss: 1.3554128408432007
iteration: 80100, loss: 1.3123211860656738
iteration: 80150, loss: 1.5098227262496948
iteration: 80200, loss: 1.4358055591583252
iteration: 80250, loss: 1.4569953680038452
iteration: 80300, loss: 1.6893080472946167
iteration: 80350, loss: 1.762169361114502
iteration: 80400, loss: 1.791744589805603
iteration: 80450, loss: 1.253527283668518
iteration: 80500, loss: 1.2344245910644531
iteration: 80550, loss: 1.162361979484558
epoch 60, loss: 1.4507697346758595
epoch 61
iteration: 80600, loss: 1.2768555879592896
iteration: 80650, loss: 1.141501545906067
iteration: 80700, loss: 1.279133677482605
iteration: 80750, loss: 1.627742886543274
iteration: 80800, loss: 2.0580785274505615
iteration: 80850, loss: 1.801456093788147
iteration: 80900, loss: 1.49188232421875
iteration: 80950, loss: 1.084664225578308
iteration: 81000, loss: 1.3885245323181152
iteration: 81050, loss: 1.6050933599472046
iteration: 81100, loss: 1.223159670829773
iteration: 81150, loss: 0.8553885221481323
iteration: 81200, loss: 1.593921184539795
iteration: 81250, loss: 2.0062661170959473
iteration: 81300, loss: 1.6696064472198486
iteration: 81350, loss: 1.2434635162353516
iteration: 81400, loss: 1.0270670652389526
iteration: 81450, loss: 1.4473532438278198
iteration: 81500, loss: 1.5276156663894653
iteration: 81550, loss: 1.4092135429382324
iteration: 81600, loss: 1.1415176391601562
iteration: 81650, loss: 2.797254800796509
iteration: 81700, loss: 1.2493796348571777
iteration: 81750, loss: 1.2819863557815552
iteration: 81800, loss: 1.3023912906646729
iteration: 81850, loss: 1.9533287286758423
iteration: 81900, loss: 1.7258110046386719
epoch 61, loss: 1.4553367721211155
epoch 62
iteration: 81950, loss: 1.6606407165527344
iteration: 82000, loss: 1.3998552560806274
iteration: 82050, loss: 1.3224091529846191
iteration: 82100, loss: 1.1400123834609985
iteration: 82150, loss: 1.5388166904449463
iteration: 82200, loss: 1.5193203687667847
iteration: 82250, loss: 1.1246923208236694
iteration: 82300, loss: 1.208589792251587
iteration: 82350, loss: 1.214197039604187
iteration: 82400, loss: 1.6181923151016235
iteration: 82450, loss: 1.1978744268417358
iteration: 82500, loss: 1.6970046758651733
iteration: 82550, loss: 1.1784220933914185
iteration: 82600, loss: 1.7427042722702026
iteration: 82650, loss: 1.3406579494476318
iteration: 82700, loss: 1.4010140895843506
iteration: 82750, loss: 1.6126527786254883
iteration: 82800, loss: 1.6589481830596924
iteration: 82850, loss: 0.9988648891448975
iteration: 82900, loss: 1.2654831409454346
iteration: 82950, loss: 1.4280036687850952
iteration: 83000, loss: 1.331952452659607
iteration: 83050, loss: 1.5565485954284668
iteration: 83100, loss: 1.1345832347869873
iteration: 83150, loss: 1.2862253189086914
iteration: 83200, loss: 1.1328710317611694
epoch 62, loss: 1.4466263882935668
epoch 63
iteration: 83250, loss: 1.1638723611831665
iteration: 83300, loss: 1.6029127836227417
iteration: 83350, loss: 1.5127434730529785
iteration: 83400, loss: 1.2335323095321655
iteration: 83450, loss: 1.197912335395813
iteration: 83500, loss: 1.292785406112671
iteration: 83550, loss: 1.577990174293518
iteration: 83600, loss: 1.6873821020126343
iteration: 83650, loss: 1.1300318241119385
iteration: 83700, loss: 1.512223243713379
iteration: 83750, loss: 1.4162218570709229
iteration: 83800, loss: 1.1199707984924316
iteration: 83850, loss: 1.6453412771224976
iteration: 83900, loss: 1.6265455484390259
iteration: 83950, loss: 2.1171014308929443
iteration: 84000, loss: 0.8992775678634644
iteration: 84050, loss: 1.3253910541534424
iteration: 84100, loss: 1.4272524118423462
iteration: 84150, loss: 1.3746856451034546
iteration: 84200, loss: 1.2316142320632935
iteration: 84250, loss: 1.08906888961792
iteration: 84300, loss: 1.4836925268173218
iteration: 84350, loss: 1.3022829294204712
iteration: 84400, loss: 1.564959168434143
iteration: 84450, loss: 1.5379855632781982
iteration: 84500, loss: 1.6194900274276733
epoch 63, loss: 1.444253671451233
epoch 64
iteration: 84550, loss: 1.4927797317504883
iteration: 84600, loss: 1.5023694038391113
iteration: 84650, loss: 1.785343050956726
iteration: 84700, loss: 1.224339246749878
iteration: 84750, loss: 1.3932347297668457
iteration: 84800, loss: 1.438949704170227
iteration: 84850, loss: 1.2451680898666382
iteration: 84900, loss: 1.5108307600021362
iteration: 84950, loss: 1.3647783994674683
iteration: 85000, loss: 1.623395323753357
iteration: 85050, loss: 1.1515564918518066
iteration: 85100, loss: 1.0359232425689697
iteration: 85150, loss: 1.8921092748641968
iteration: 85200, loss: 1.4414668083190918
iteration: 85250, loss: 1.355606198310852
iteration: 85300, loss: 2.1105124950408936
iteration: 85350, loss: 1.3814417123794556
iteration: 85400, loss: 1.1106058359146118
iteration: 85450, loss: 1.1299761533737183
iteration: 85500, loss: 1.6172354221343994
iteration: 85550, loss: 1.5044516324996948
iteration: 85600, loss: 1.3333125114440918
iteration: 85650, loss: 1.3266583681106567
iteration: 85700, loss: 1.2946898937225342
iteration: 85750, loss: 1.289746880531311
iteration: 85800, loss: 1.076130986213684
iteration: 85850, loss: 1.5646415948867798
epoch 64, loss: 1.4464867223741429
epoch 65
iteration: 85900, loss: 1.3030911684036255
iteration: 85950, loss: 1.2038390636444092
iteration: 86000, loss: 1.334706425666809
iteration: 86050, loss: 1.1920788288116455
iteration: 86100, loss: 1.4484820365905762
iteration: 86150, loss: 1.2492655515670776
iteration: 86200, loss: 1.1201828718185425
iteration: 86250, loss: 1.8765461444854736
iteration: 86300, loss: 1.2529246807098389
iteration: 86350, loss: 1.2266863584518433
iteration: 86400, loss: 1.7306257486343384
iteration: 86450, loss: 1.1208391189575195
iteration: 86500, loss: 1.176811695098877
iteration: 86550, loss: 1.6576359272003174
iteration: 86600, loss: 1.077313780784607
iteration: 86650, loss: 1.129495620727539
iteration: 86700, loss: 1.718427300453186
iteration: 86750, loss: 2.0140016078948975
iteration: 86800, loss: 1.4362419843673706
iteration: 86850, loss: 1.3698967695236206
iteration: 86900, loss: 1.5675249099731445
iteration: 86950, loss: 1.5116794109344482
iteration: 87000, loss: 1.3936028480529785
iteration: 87050, loss: 1.5181615352630615
iteration: 87100, loss: 1.1662867069244385
iteration: 87150, loss: 1.7567059993743896
epoch 65, loss: 1.4456262859625983
epoch 66
iteration: 87200, loss: 1.2833259105682373
iteration: 87250, loss: 1.4861308336257935
iteration: 87300, loss: 1.9161710739135742
iteration: 87350, loss: 1.2051888704299927
iteration: 87400, loss: 1.8068993091583252
iteration: 87450, loss: 1.1438477039337158
iteration: 87500, loss: 2.3230440616607666
iteration: 87550, loss: 1.5667153596878052
iteration: 87600, loss: 1.66877019405365
iteration: 87650, loss: 1.962613582611084
iteration: 87700, loss: 1.2016724348068237
iteration: 87750, loss: 1.6521848440170288
iteration: 87800, loss: 1.409846544265747
iteration: 87850, loss: 1.010267972946167
iteration: 87900, loss: 1.1847025156021118
iteration: 87950, loss: 1.8473999500274658
iteration: 88000, loss: 1.995947003364563
iteration: 88050, loss: 1.734188437461853
iteration: 88100, loss: 1.5356489419937134
iteration: 88150, loss: 1.3149189949035645
iteration: 88200, loss: 1.7263795137405396
iteration: 88250, loss: 1.2517203092575073
iteration: 88300, loss: 1.465333104133606
iteration: 88350, loss: 1.512625813484192
iteration: 88400, loss: 1.691645860671997
iteration: 88450, loss: 1.3761323690414429
iteration: 88500, loss: 1.2211239337921143
epoch 66, loss: 1.4473982172183757
epoch 67
iteration: 88550, loss: 1.3291715383529663
iteration: 88600, loss: 1.2648388147354126
iteration: 88650, loss: 1.6747148036956787
iteration: 88700, loss: 1.8681063652038574
iteration: 88750, loss: 1.4679123163223267
iteration: 88800, loss: 1.778262734413147
iteration: 88850, loss: 1.5588308572769165
iteration: 88900, loss: 1.2513571977615356
iteration: 88950, loss: 1.6530967950820923
iteration: 89000, loss: 1.2317613363265991
iteration: 89050, loss: 1.3833194971084595
iteration: 89100, loss: 1.512273907661438
iteration: 89150, loss: 1.5765199661254883
iteration: 89200, loss: 1.1737732887268066
iteration: 89250, loss: 1.4624383449554443
iteration: 89300, loss: 1.3525747060775757
iteration: 89350, loss: 2.3098976612091064
iteration: 89400, loss: 1.57136070728302
iteration: 89450, loss: 1.7777379751205444
iteration: 89500, loss: 1.1337536573410034
iteration: 89550, loss: 1.3905205726623535
iteration: 89600, loss: 1.5721091032028198
iteration: 89650, loss: 1.8073912858963013
iteration: 89700, loss: 1.0157885551452637
iteration: 89750, loss: 1.323336124420166
iteration: 89800, loss: 1.408689260482788
epoch 67, loss: 1.4370321355908122
epoch 68
iteration: 89850, loss: 1.1033964157104492
iteration: 89900, loss: 1.3681124448776245
iteration: 89950, loss: 1.2771728038787842
iteration: 90000, loss: 1.5169709920883179
iteration: 90050, loss: 1.1702114343643188
iteration: 90100, loss: 1.847698450088501
iteration: 90150, loss: 1.9370819330215454
iteration: 90200, loss: 1.6409038305282593
iteration: 90250, loss: 1.4607884883880615
iteration: 90300, loss: 2.2877445220947266
iteration: 90350, loss: 1.6101515293121338
iteration: 90400, loss: 1.2755656242370605
iteration: 90450, loss: 1.3393151760101318
iteration: 90500, loss: 1.5620509386062622
iteration: 90550, loss: 1.022748589515686
iteration: 90600, loss: 1.3667861223220825
iteration: 90650, loss: 1.2711986303329468
iteration: 90700, loss: 1.429578423500061
iteration: 90750, loss: 1.6335874795913696
iteration: 90800, loss: 1.8896242380142212
iteration: 90850, loss: 1.477394938468933
iteration: 90900, loss: 0.8683629035949707
iteration: 90950, loss: 1.2733403444290161
iteration: 91000, loss: 1.9222313165664673
iteration: 91050, loss: 1.3754281997680664
iteration: 91100, loss: 1.3984923362731934
epoch 68, loss: 1.4307613638063141
epoch 69
iteration: 91150, loss: 1.5031641721725464
iteration: 91200, loss: 0.8659012317657471
iteration: 91250, loss: 1.0806492567062378
iteration: 91300, loss: 1.4672062397003174
iteration: 91350, loss: 1.0586864948272705
iteration: 91400, loss: 1.5151668787002563
iteration: 91450, loss: 1.740167498588562
iteration: 91500, loss: 1.3264403343200684
iteration: 91550, loss: 1.922738790512085
iteration: 91600, loss: 1.0415170192718506
iteration: 91650, loss: 1.5632715225219727
iteration: 91700, loss: 0.9235707521438599
iteration: 91750, loss: 1.375535011291504
iteration: 91800, loss: 1.6043709516525269
iteration: 91850, loss: 1.2723852396011353
iteration: 91900, loss: 1.2045865058898926
iteration: 91950, loss: 1.3722728490829468
iteration: 92000, loss: 1.4417539834976196
iteration: 92050, loss: 1.621405839920044
iteration: 92100, loss: 1.199000358581543
iteration: 92150, loss: 1.7147539854049683
iteration: 92200, loss: 1.368896484375
iteration: 92250, loss: 1.09760582447052
iteration: 92300, loss: 1.2987644672393799
iteration: 92350, loss: 1.1099745035171509
iteration: 92400, loss: 1.5433298349380493
iteration: 92450, loss: 1.3894500732421875
epoch 69, loss: 1.4231703627414036
epoch 70
iteration: 92500, loss: 1.1953456401824951
iteration: 92550, loss: 1.3729981184005737
iteration: 92600, loss: 1.7842109203338623
iteration: 92650, loss: 1.5304747819900513
iteration: 92700, loss: 1.176216721534729
iteration: 92750, loss: 1.5553903579711914
iteration: 92800, loss: 1.5336664915084839
iteration: 92850, loss: 1.6472234725952148
iteration: 92900, loss: 1.6032484769821167
iteration: 92950, loss: 1.3042231798171997
iteration: 93000, loss: 1.417210340499878
iteration: 93050, loss: 0.9828718304634094
iteration: 93100, loss: 1.4531173706054688
iteration: 93150, loss: 1.218644380569458
iteration: 93200, loss: 1.7511787414550781
iteration: 93250, loss: 1.440721869468689
iteration: 93300, loss: 1.0818536281585693
iteration: 93350, loss: 1.240878701210022
iteration: 93400, loss: 1.309399127960205
iteration: 93450, loss: 1.4509711265563965
iteration: 93500, loss: 1.9063345193862915
iteration: 93550, loss: 1.3545870780944824
iteration: 93600, loss: 1.6521400213241577
iteration: 93650, loss: 1.1494895219802856
iteration: 93700, loss: 1.3907390832901
iteration: 93750, loss: 1.1349499225616455
epoch 70, loss: 1.4232726058761467
epoch 71
iteration: 93800, loss: 1.8138936758041382
iteration: 93850, loss: 1.296129584312439
iteration: 93900, loss: 1.6418521404266357
iteration: 93950, loss: 1.4353889226913452
iteration: 94000, loss: 1.3082655668258667
iteration: 94050, loss: 1.182005524635315
iteration: 94100, loss: 1.4926931858062744
iteration: 94150, loss: 1.4618185758590698
iteration: 94200, loss: 1.7390203475952148
iteration: 94250, loss: 1.3941236734390259
iteration: 94300, loss: 1.9204639196395874
iteration: 94350, loss: 1.2982597351074219
iteration: 94400, loss: 1.3545403480529785
iteration: 94450, loss: 1.5848629474639893
iteration: 94500, loss: 1.6993988752365112
iteration: 94550, loss: 1.0870983600616455
iteration: 94600, loss: 1.781089186668396
iteration: 94650, loss: 1.1070845127105713
iteration: 94700, loss: 1.3183526992797852
iteration: 94750, loss: 1.6854968070983887
iteration: 94800, loss: 1.3676137924194336
iteration: 94850, loss: 1.1386138200759888
iteration: 94900, loss: 1.758774995803833
iteration: 94950, loss: 1.1501872539520264
iteration: 95000, loss: 1.1821550130844116
iteration: 95050, loss: 1.7010729312896729
iteration: 95100, loss: 1.0334609746932983
epoch 71, loss: 1.4150399927610255
epoch 72
iteration: 95150, loss: 1.2785310745239258
iteration: 95200, loss: 1.3060990571975708
iteration: 95250, loss: 1.4254807233810425
iteration: 95300, loss: 1.2443287372589111
iteration: 95350, loss: 1.173142433166504
iteration: 95400, loss: 1.426791787147522
iteration: 95450, loss: 1.424215316772461
iteration: 95500, loss: 1.2147903442382812
iteration: 95550, loss: 1.1434926986694336
iteration: 95600, loss: 1.3480491638183594
iteration: 95650, loss: 1.2375136613845825
iteration: 95700, loss: 1.2109392881393433
iteration: 95750, loss: 1.6949470043182373
iteration: 95800, loss: 1.6084805727005005
iteration: 95850, loss: 1.4091686010360718
iteration: 95900, loss: 1.7658594846725464
iteration: 95950, loss: 1.536964774131775
iteration: 96000, loss: 1.541215419769287
iteration: 96050, loss: 2.0946600437164307
iteration: 96100, loss: 1.112415075302124
iteration: 96150, loss: 1.2071512937545776
iteration: 96200, loss: 1.0792992115020752
iteration: 96250, loss: 1.2037713527679443
iteration: 96300, loss: 1.4377074241638184
iteration: 96350, loss: 1.447556495666504
iteration: 96400, loss: 1.3946174383163452
epoch 72, loss: 1.4273815634573195
epoch 73
iteration: 96450, loss: 1.6774755716323853
iteration: 96500, loss: 1.3595176935195923
iteration: 96550, loss: 1.0043612718582153
iteration: 96600, loss: 1.1567153930664062
iteration: 96650, loss: 1.427196741104126
iteration: 96700, loss: 1.1449429988861084
iteration: 96750, loss: 1.6398351192474365
iteration: 96800, loss: 1.3567553758621216
iteration: 96850, loss: 1.3992934226989746
iteration: 96900, loss: 1.7057981491088867
iteration: 96950, loss: 1.196631669998169
iteration: 97000, loss: 1.2814620733261108
iteration: 97050, loss: 1.121119737625122
iteration: 97100, loss: 1.1317408084869385
iteration: 97150, loss: 1.4441543817520142
iteration: 97200, loss: 1.290173053741455
iteration: 97250, loss: 1.2410930395126343
iteration: 97300, loss: 1.6459546089172363
iteration: 97350, loss: 1.3358145952224731
iteration: 97400, loss: 1.1290769577026367
iteration: 97450, loss: 1.231261134147644
iteration: 97500, loss: 1.4878408908843994
iteration: 97550, loss: 1.5054025650024414
iteration: 97600, loss: 1.2616511583328247
iteration: 97650, loss: 1.8980942964553833
iteration: 97700, loss: 1.4673552513122559
iteration: 97750, loss: 1.178823471069336
epoch 73, loss: 1.4306808759947374
epoch 74
iteration: 97800, loss: 1.0212723016738892
iteration: 97850, loss: 0.7510984539985657
iteration: 97900, loss: 1.357655644416809
iteration: 97950, loss: 1.1526412963867188
iteration: 98000, loss: 1.297914743423462
iteration: 98050, loss: 1.721929669380188
iteration: 98100, loss: 1.1188839673995972
iteration: 98150, loss: 1.2959214448928833
iteration: 98200, loss: 1.6727122068405151
iteration: 98250, loss: 0.8978567719459534
iteration: 98300, loss: 1.3922686576843262
iteration: 98350, loss: 1.3247673511505127
iteration: 98400, loss: 1.3738460540771484
iteration: 98450, loss: 1.2276406288146973
iteration: 98500, loss: 1.6075122356414795
iteration: 98550, loss: 1.7597625255584717
iteration: 98600, loss: 1.5956737995147705
iteration: 98650, loss: 1.049921989440918
iteration: 98700, loss: 2.570805788040161
iteration: 98750, loss: 1.2921909093856812
iteration: 98800, loss: 1.898182988166809
iteration: 98850, loss: 1.6428791284561157
iteration: 98900, loss: 1.44198477268219
iteration: 98950, loss: 1.6075427532196045
iteration: 99000, loss: 1.6292895078659058
iteration: 99050, loss: 1.074997901916504
epoch 74, loss: 1.4268132969920322
epoch 75
iteration: 99100, loss: 1.1270272731781006
iteration: 99150, loss: 1.4532780647277832
iteration: 99200, loss: 1.881404995918274
iteration: 99250, loss: 1.4645612239837646
iteration: 99300, loss: 1.1877027750015259
iteration: 99350, loss: 1.060202956199646
iteration: 99400, loss: 1.3733246326446533
iteration: 99450, loss: 1.4948469400405884
iteration: 99500, loss: 1.4207980632781982
iteration: 99550, loss: 1.5593045949935913
iteration: 99600, loss: 1.2267011404037476
iteration: 99650, loss: 1.6212389469146729
iteration: 99700, loss: 1.1048336029052734
iteration: 99750, loss: 1.603336215019226
iteration: 99800, loss: 1.1157182455062866
iteration: 99850, loss: 1.1598914861679077
iteration: 99900, loss: 1.2844841480255127
iteration: 99950, loss: 1.4424349069595337
iteration: 100000, loss: 1.0302408933639526
iteration: 100050, loss: 1.9826675653457642
iteration: 100100, loss: 1.3180872201919556
iteration: 100150, loss: 1.0219646692276
iteration: 100200, loss: 1.3303039073944092
iteration: 100250, loss: 1.1426050662994385
iteration: 100300, loss: 1.096300721168518
iteration: 100350, loss: 1.3981685638427734
epoch 75, loss: 1.4225330518345396
epoch 76
iteration: 100400, loss: 1.6964881420135498
iteration: 100450, loss: 1.4351060390472412
iteration: 100500, loss: 1.8501888513565063
iteration: 100550, loss: 1.1898550987243652
iteration: 100600, loss: 1.767445683479309
iteration: 100650, loss: 1.0787161588668823
iteration: 100700, loss: 1.5090421438217163
iteration: 100750, loss: 1.4138826131820679
iteration: 100800, loss: 1.3407163619995117
iteration: 100850, loss: 1.1317106485366821
iteration: 100900, loss: 1.6925932168960571
iteration: 100950, loss: 1.1583456993103027
iteration: 101000, loss: 1.2793656587600708
iteration: 101050, loss: 1.1154879331588745
iteration: 101100, loss: 1.9007428884506226
iteration: 101150, loss: 1.2762629985809326
iteration: 101200, loss: 1.1611499786376953
iteration: 101250, loss: 1.1329468488693237
iteration: 101300, loss: 1.060957670211792
iteration: 101350, loss: 1.1352405548095703
iteration: 101400, loss: 1.4977914094924927
iteration: 101450, loss: 1.224796175956726
iteration: 101500, loss: 1.296454668045044
iteration: 101550, loss: 1.5693777799606323
iteration: 101600, loss: 1.1703038215637207
iteration: 101650, loss: 1.4550055265426636
iteration: 101700, loss: 1.1711065769195557
epoch 76, loss: 1.416267624776546
epoch 77
iteration: 101750, loss: 1.8555850982666016
iteration: 101800, loss: 1.2221688032150269
iteration: 101850, loss: 1.6065634489059448
iteration: 101900, loss: 1.234199047088623
iteration: 101950, loss: 1.0817935466766357
iteration: 102000, loss: 1.1723999977111816
iteration: 102050, loss: 1.5752843618392944
iteration: 102100, loss: 1.2702480554580688
iteration: 102150, loss: 1.5620652437210083
iteration: 102200, loss: 1.5742636919021606
iteration: 102250, loss: 1.4174611568450928
iteration: 102300, loss: 1.4461253881454468
iteration: 102350, loss: 1.5084209442138672
iteration: 102400, loss: 1.5913408994674683
iteration: 102450, loss: 1.4298909902572632
iteration: 102500, loss: 1.7839546203613281
iteration: 102550, loss: 1.1966184377670288
iteration: 102600, loss: 1.2033817768096924
iteration: 102650, loss: 1.228046178817749
iteration: 102700, loss: 1.4776719808578491
iteration: 102750, loss: 1.1776951551437378
iteration: 102800, loss: 1.6827034950256348
iteration: 102850, loss: 1.2018784284591675
iteration: 102900, loss: 1.5099283456802368
iteration: 102950, loss: 1.7477424144744873
iteration: 103000, loss: 1.4157150983810425
epoch 77, loss: 1.4115081614329212
epoch 78
iteration: 103050, loss: 1.2876890897750854
iteration: 103100, loss: 1.2267587184906006
iteration: 103150, loss: 1.7547587156295776
iteration: 103200, loss: 1.758608341217041
iteration: 103250, loss: 1.77830970287323
iteration: 103300, loss: 1.445218801498413
iteration: 103350, loss: 1.2808376550674438
iteration: 103400, loss: 1.5966817140579224
iteration: 103450, loss: 1.139149785041809
iteration: 103500, loss: 2.1190781593322754
iteration: 103550, loss: 1.4204157590866089
iteration: 103600, loss: 1.3312857151031494
iteration: 103650, loss: 1.3335137367248535
iteration: 103700, loss: 1.3558204174041748
iteration: 103750, loss: 1.5452423095703125
iteration: 103800, loss: 1.2223886251449585
iteration: 103850, loss: 1.309830665588379
iteration: 103900, loss: 1.4688551425933838
iteration: 103950, loss: 1.929660677909851
iteration: 104000, loss: 1.6209311485290527
iteration: 104050, loss: 1.5018430948257446
iteration: 104100, loss: 1.3912426233291626
iteration: 104150, loss: 1.3457132577896118
iteration: 104200, loss: 2.124000310897827
iteration: 104250, loss: 1.687437891960144
iteration: 104300, loss: 1.5294636487960815
iteration: 104350, loss: 1.119956374168396
epoch 78, loss: 1.4184046378086057
epoch 79
iteration: 104400, loss: 1.7320599555969238
iteration: 104450, loss: 1.598701000213623
iteration: 104500, loss: 1.1297507286071777
iteration: 104550, loss: 1.2712140083312988
iteration: 104600, loss: 1.6795743703842163
iteration: 104650, loss: 1.3199114799499512
iteration: 104700, loss: 1.5977693796157837
iteration: 104750, loss: 1.429307460784912
iteration: 104800, loss: 1.7130048274993896
iteration: 104850, loss: 1.50589120388031
iteration: 104900, loss: 1.6426687240600586
iteration: 104950, loss: 1.8416433334350586
iteration: 105000, loss: 1.2927345037460327
iteration: 105050, loss: 0.9895015954971313
iteration: 105100, loss: 1.4831368923187256
iteration: 105150, loss: 1.384251356124878
iteration: 105200, loss: 1.7789703607559204
iteration: 105250, loss: 1.1964259147644043
iteration: 105300, loss: 1.2273870706558228
iteration: 105350, loss: 1.0388672351837158
iteration: 105400, loss: 1.6483153104782104
iteration: 105450, loss: 1.5238696336746216
iteration: 105500, loss: 1.0246694087982178
iteration: 105550, loss: 1.4368149042129517
iteration: 105600, loss: 1.2319576740264893
iteration: 105650, loss: 1.7634440660476685
epoch 79, loss: 1.411861498218273
epoch 80
iteration: 105700, loss: 1.1891270875930786
iteration: 105750, loss: 1.4302481412887573
iteration: 105800, loss: 1.2691645622253418
iteration: 105850, loss: 1.4998897314071655
iteration: 105900, loss: 1.1386786699295044
iteration: 105950, loss: 1.1313989162445068
iteration: 106000, loss: 1.239896535873413
iteration: 106050, loss: 1.3475866317749023
iteration: 106100, loss: 1.5976605415344238
iteration: 106150, loss: 0.9599311947822571
iteration: 106200, loss: 1.0836172103881836
iteration: 106250, loss: 0.9804133176803589
iteration: 106300, loss: 1.1386431455612183
iteration: 106350, loss: 1.424508810043335
iteration: 106400, loss: 1.084007978439331
iteration: 106450, loss: 1.2674438953399658
iteration: 106500, loss: 1.4481678009033203
iteration: 106550, loss: 1.598697304725647
iteration: 106600, loss: 1.0007091760635376
iteration: 106650, loss: 1.0217617750167847
iteration: 106700, loss: 1.6086260080337524
iteration: 106750, loss: 1.0228135585784912
iteration: 106800, loss: 1.1675556898117065
iteration: 106850, loss: 1.6464550495147705
iteration: 106900, loss: 1.196470022201538
iteration: 106950, loss: 1.8686435222625732
iteration: 107000, loss: 1.4111926555633545
epoch 80, loss: 1.401306213831834
epoch 81
iteration: 107050, loss: 1.0589579343795776
iteration: 107100, loss: 1.4832178354263306
iteration: 107150, loss: 1.3882640600204468
iteration: 107200, loss: 1.3812488317489624
iteration: 107250, loss: 0.9872804880142212
iteration: 107300, loss: 1.4427006244659424
iteration: 107350, loss: 1.2533068656921387
iteration: 107400, loss: 1.1375597715377808
iteration: 107450, loss: 1.6989572048187256
iteration: 107500, loss: 1.317869782447815
iteration: 107550, loss: 1.36712646484375
iteration: 107600, loss: 1.4677659273147583
iteration: 107650, loss: 1.4815770387649536
iteration: 107700, loss: 1.4085215330123901
iteration: 107750, loss: 1.0901529788970947
iteration: 107800, loss: 1.2553945779800415
iteration: 107850, loss: 1.5494706630706787
iteration: 107900, loss: 1.3168810606002808
iteration: 107950, loss: 1.6115270853042603
iteration: 108000, loss: 1.42047917842865
iteration: 108050, loss: 1.2670248746871948
iteration: 108100, loss: 1.2922296524047852
iteration: 108150, loss: 1.4507120847702026
iteration: 108200, loss: 1.2510976791381836
iteration: 108250, loss: 1.6731058359146118
iteration: 108300, loss: 1.2633013725280762
epoch 81, loss: 1.4160007309439957
epoch 82
iteration: 108350, loss: 1.1982452869415283
iteration: 108400, loss: 1.3884449005126953
iteration: 108450, loss: 1.6719119548797607
iteration: 108500, loss: 1.123271107673645
iteration: 108550, loss: 1.2474455833435059
iteration: 108600, loss: 1.3612724542617798
iteration: 108650, loss: 1.017599105834961
iteration: 108700, loss: 2.0934929847717285
iteration: 108750, loss: 1.550173282623291
iteration: 108800, loss: 1.4403164386749268
iteration: 108850, loss: 1.5129450559616089
iteration: 108900, loss: 1.9521405696868896
iteration: 108950, loss: 1.5644193887710571
iteration: 109000, loss: 1.4565393924713135
iteration: 109050, loss: 1.4858436584472656
iteration: 109100, loss: 1.6061943769454956
iteration: 109150, loss: 1.4763247966766357
iteration: 109200, loss: 1.2019577026367188
iteration: 109250, loss: 0.9345115423202515
iteration: 109300, loss: 1.8909555673599243
iteration: 109350, loss: 1.354644536972046
iteration: 109400, loss: 1.4608546495437622
iteration: 109450, loss: 1.1097371578216553
iteration: 109500, loss: 1.4792020320892334
iteration: 109550, loss: 1.221808910369873
iteration: 109600, loss: 1.6043400764465332
epoch 82, loss: 1.4087338958693318
epoch 83
iteration: 109650, loss: 1.182667851448059
iteration: 109700, loss: 1.0979840755462646
iteration: 109750, loss: 1.5132180452346802
iteration: 109800, loss: 1.2145869731903076
iteration: 109850, loss: 1.1542400121688843
iteration: 109900, loss: 1.0540831089019775
iteration: 109950, loss: 1.560130000114441
iteration: 110000, loss: 1.386616826057434
iteration: 110050, loss: 1.2762205600738525
iteration: 110100, loss: 1.0546355247497559
iteration: 110150, loss: 1.2962075471878052
iteration: 110200, loss: 1.6288623809814453
iteration: 110250, loss: 1.033653974533081
iteration: 110300, loss: 1.7122070789337158
iteration: 110350, loss: 1.6764980554580688
iteration: 110400, loss: 1.5378562211990356
iteration: 110450, loss: 1.0605064630508423
iteration: 110500, loss: 1.5571011304855347
iteration: 110550, loss: 1.179486870765686
iteration: 110600, loss: 1.129579782485962
iteration: 110650, loss: 1.5141160488128662
iteration: 110700, loss: 1.488389492034912
iteration: 110750, loss: 1.4983259439468384
iteration: 110800, loss: 1.0248125791549683
iteration: 110850, loss: 1.30781090259552
iteration: 110900, loss: 1.690779685974121
iteration: 110950, loss: 1.405735731124878
epoch 83, loss: 1.3972785563996748
epoch 84
iteration: 111000, loss: 1.4160367250442505
iteration: 111050, loss: 1.3440170288085938
iteration: 111100, loss: 0.9876961708068848
iteration: 111150, loss: 1.463036298751831
iteration: 111200, loss: 1.6507725715637207
iteration: 111250, loss: 1.510762333869934
iteration: 111300, loss: 1.2640677690505981
iteration: 111350, loss: 1.0919089317321777
iteration: 111400, loss: 1.6955246925354004
iteration: 111450, loss: 1.3482563495635986
iteration: 111500, loss: 1.6743888854980469
iteration: 111550, loss: 1.4450699090957642
iteration: 111600, loss: 1.5571260452270508
iteration: 111650, loss: 1.2238924503326416
iteration: 111700, loss: 1.3726859092712402
iteration: 111750, loss: 1.5376274585723877
iteration: 111800, loss: 2.0579864978790283
iteration: 111850, loss: 1.1007779836654663
iteration: 111900, loss: 1.239138126373291
iteration: 111950, loss: 1.004462480545044
iteration: 112000, loss: 1.3544411659240723
iteration: 112050, loss: 1.730729103088379
iteration: 112100, loss: 1.5264616012573242
iteration: 112150, loss: 1.43790602684021
iteration: 112200, loss: 1.168953776359558
iteration: 112250, loss: 1.2572039365768433
epoch 84, loss: 1.4001719573137326
epoch 85
iteration: 112300, loss: 1.0910189151763916
iteration: 112350, loss: 0.982239305973053
iteration: 112400, loss: 1.6635158061981201
iteration: 112450, loss: 1.4438987970352173
iteration: 112500, loss: 1.8699589967727661
iteration: 112550, loss: 1.434725046157837
iteration: 112600, loss: 1.0522639751434326
iteration: 112650, loss: 1.2626855373382568
iteration: 112700, loss: 1.2101564407348633
iteration: 112750, loss: 1.554665207862854
iteration: 112800, loss: 1.4475891590118408
iteration: 112850, loss: 1.0963901281356812
iteration: 112900, loss: 1.2665234804153442
iteration: 112950, loss: 1.473006010055542
iteration: 113000, loss: 1.0628694295883179
iteration: 113050, loss: 1.4399522542953491
iteration: 113100, loss: 1.797011375427246
iteration: 113150, loss: 1.462748408317566
iteration: 113200, loss: 1.5611581802368164
iteration: 113250, loss: 1.2385070323944092
iteration: 113300, loss: 1.3636245727539062
iteration: 113350, loss: 1.4989937543869019
iteration: 113400, loss: 1.1661641597747803
iteration: 113450, loss: 1.3159571886062622
iteration: 113500, loss: 1.7179155349731445
iteration: 113550, loss: 1.6551657915115356
iteration: 113600, loss: 1.235727310180664
epoch 85, loss: 1.3917288595251915
epoch 86
iteration: 113650, loss: 1.404535174369812
iteration: 113700, loss: 1.2433949708938599
iteration: 113750, loss: 0.853016197681427
iteration: 113800, loss: 2.049126625061035
iteration: 113850, loss: 1.095409631729126
iteration: 113900, loss: 1.9679666757583618
iteration: 113950, loss: 1.4584145545959473
iteration: 114000, loss: 1.169715166091919
iteration: 114050, loss: 1.820989727973938
iteration: 114100, loss: 1.7750283479690552
iteration: 114150, loss: 1.2518465518951416
iteration: 114200, loss: 1.0683631896972656
iteration: 114250, loss: 1.5675281286239624
iteration: 114300, loss: 1.3281818628311157
iteration: 114350, loss: 1.9172998666763306
iteration: 114400, loss: 1.335524559020996
iteration: 114450, loss: 1.1807137727737427
iteration: 114500, loss: 1.7264410257339478
iteration: 114550, loss: 1.3645906448364258
iteration: 114600, loss: 1.5602214336395264
iteration: 114650, loss: 1.5481486320495605
iteration: 114700, loss: 1.2515782117843628
iteration: 114750, loss: 1.2552660703659058
iteration: 114800, loss: 1.4130327701568604
iteration: 114850, loss: 1.726029634475708
iteration: 114900, loss: 1.4236446619033813
epoch 86, loss: 1.3939767934064766
epoch 87
iteration: 114950, loss: 1.1621710062026978
iteration: 115000, loss: 1.0863031148910522
iteration: 115050, loss: 1.5977964401245117
iteration: 115100, loss: 1.2997405529022217
iteration: 115150, loss: 1.8009096384048462
iteration: 115200, loss: 1.6372523307800293
iteration: 115250, loss: 0.7638908624649048
iteration: 115300, loss: 1.211191177368164
iteration: 115350, loss: 1.4554247856140137
iteration: 115400, loss: 1.3005527257919312
iteration: 115450, loss: 1.4748568534851074
iteration: 115500, loss: 1.5361701250076294
iteration: 115550, loss: 1.2464563846588135
iteration: 115600, loss: 1.640454888343811
iteration: 115650, loss: 2.0111443996429443
iteration: 115700, loss: 1.5417850017547607
iteration: 115750, loss: 1.4670944213867188
iteration: 115800, loss: 1.3374292850494385
iteration: 115850, loss: 1.0096464157104492
iteration: 115900, loss: 1.138812780380249
iteration: 115950, loss: 1.323162317276001
iteration: 116000, loss: 1.3918828964233398
iteration: 116050, loss: 1.3185659646987915
iteration: 116100, loss: 1.1695728302001953
iteration: 116150, loss: 1.8092870712280273
iteration: 116200, loss: 1.4666677713394165
epoch 87, loss: 1.398171295573831
epoch 88
iteration: 116250, loss: 1.2762075662612915
iteration: 116300, loss: 1.3704440593719482
iteration: 116350, loss: 1.16705322265625
iteration: 116400, loss: 1.2060837745666504
iteration: 116450, loss: 1.3290904760360718
iteration: 116500, loss: 1.3624070882797241
iteration: 116550, loss: 1.4626373052597046
iteration: 116600, loss: 1.2541500329971313
iteration: 116650, loss: 1.3871890306472778
iteration: 116700, loss: 1.7510184049606323
iteration: 116750, loss: 1.3485281467437744
iteration: 116800, loss: 1.2138453722000122
iteration: 116850, loss: 0.9569456577301025
iteration: 116900, loss: 1.9206492900848389
iteration: 116950, loss: 1.5074737071990967
iteration: 117000, loss: 1.3736251592636108
iteration: 117050, loss: 1.31449294090271
iteration: 117100, loss: 1.2612329721450806
iteration: 117150, loss: 1.5912754535675049
iteration: 117200, loss: 1.7423288822174072
iteration: 117250, loss: 1.8946313858032227
iteration: 117300, loss: 1.121484637260437
iteration: 117350, loss: 1.5038435459136963
iteration: 117400, loss: 1.4226562976837158
iteration: 117450, loss: 1.4686111211776733
iteration: 117500, loss: 1.328653335571289
iteration: 117550, loss: 1.3461567163467407
epoch 88, loss: 1.3903892996182619
epoch 89
iteration: 117600, loss: 1.116303563117981
iteration: 117650, loss: 1.797508716583252
iteration: 117700, loss: 1.1504305601119995
iteration: 117750, loss: 1.5050127506256104
iteration: 117800, loss: 1.2984180450439453
iteration: 117850, loss: 2.123347282409668
iteration: 117900, loss: 1.3633897304534912
iteration: 117950, loss: 1.4321980476379395
iteration: 118000, loss: 1.676758885383606
iteration: 118050, loss: 1.1837736368179321
iteration: 118100, loss: 1.6494297981262207
iteration: 118150, loss: 1.4907898902893066
iteration: 118200, loss: 1.5310803651809692
iteration: 118250, loss: 1.4152367115020752
iteration: 118300, loss: 1.5895695686340332
iteration: 118350, loss: 1.123157262802124
iteration: 118400, loss: 1.5017644166946411
iteration: 118450, loss: 1.3554238080978394
iteration: 118500, loss: 1.252492904663086
iteration: 118550, loss: 1.4544559717178345
iteration: 118600, loss: 1.369935393333435
iteration: 118650, loss: 1.3346675634384155
iteration: 118700, loss: 1.2421528100967407
iteration: 118750, loss: 1.4121648073196411
iteration: 118800, loss: 1.225402593612671
iteration: 118850, loss: 1.1562145948410034
epoch 89, loss: 1.3898707569829676
epoch 90
iteration: 118900, loss: 1.0903661251068115
iteration: 118950, loss: 1.1715189218521118
iteration: 119000, loss: 1.7062770128250122
iteration: 119050, loss: 1.5947622060775757
iteration: 119100, loss: 1.3250926733016968
iteration: 119150, loss: 1.4221776723861694
iteration: 119200, loss: 1.618378758430481
iteration: 119250, loss: 1.2789853811264038
iteration: 119300, loss: 1.6833748817443848
iteration: 119350, loss: 1.5161147117614746
iteration: 119400, loss: 1.6312892436981201
iteration: 119450, loss: 1.6236292123794556
iteration: 119500, loss: 1.4592489004135132
iteration: 119550, loss: 1.5650360584259033
iteration: 119600, loss: 1.5268691778182983
iteration: 119650, loss: 1.2075200080871582
iteration: 119700, loss: 1.3854084014892578
iteration: 119750, loss: 1.4745290279388428
iteration: 119800, loss: 1.1155610084533691
iteration: 119850, loss: 1.401220679283142
iteration: 119900, loss: 1.288783073425293
iteration: 119950, loss: 1.3770134449005127
iteration: 120000, loss: 1.4629656076431274
iteration: 120050, loss: 1.3849502801895142
iteration: 120100, loss: 1.9497859477996826
iteration: 120150, loss: 1.1828944683074951
iteration: 120200, loss: 1.3807295560836792
epoch 90, loss: 1.3860642351062094
epoch 91
iteration: 120250, loss: 1.3084807395935059
iteration: 120300, loss: 1.5918457508087158
iteration: 120350, loss: 1.4366930723190308
iteration: 120400, loss: 1.165748953819275
iteration: 120450, loss: 0.9645212888717651
iteration: 120500, loss: 1.8029205799102783
iteration: 120550, loss: 1.1933437585830688
iteration: 120600, loss: 1.2209055423736572
iteration: 120650, loss: 1.123482584953308
iteration: 120700, loss: 2.0525801181793213
iteration: 120750, loss: 1.7869642972946167
iteration: 120800, loss: 1.1628409624099731
iteration: 120850, loss: 1.2210952043533325
iteration: 120900, loss: 0.8963387608528137
iteration: 120950, loss: 1.4411735534667969
iteration: 121000, loss: 1.66199791431427
iteration: 121050, loss: 1.136535882949829
iteration: 121100, loss: 1.4092280864715576
iteration: 121150, loss: 1.7433797121047974
iteration: 121200, loss: 1.1148947477340698
iteration: 121250, loss: 1.3040921688079834
iteration: 121300, loss: 1.2317653894424438
iteration: 121350, loss: 1.6821140050888062
iteration: 121400, loss: 1.0850567817687988
iteration: 121450, loss: 1.6157948970794678
iteration: 121500, loss: 1.3082464933395386
epoch 91, loss: 1.3741963575105116
epoch 92
iteration: 121550, loss: 1.447808027267456
iteration: 121600, loss: 1.0813149213790894
iteration: 121650, loss: 1.9904298782348633
iteration: 121700, loss: 1.4915995597839355
iteration: 121750, loss: 1.4456943273544312
iteration: 121800, loss: 2.0093650817871094
iteration: 121850, loss: 0.8506579399108887
iteration: 121900, loss: 1.269711971282959
iteration: 121950, loss: 1.4299647808074951
iteration: 122000, loss: 1.6755861043930054
iteration: 122050, loss: 1.3756210803985596
iteration: 122100, loss: 1.7019823789596558
iteration: 122150, loss: 1.4662022590637207
iteration: 122200, loss: 1.6192007064819336
iteration: 122250, loss: 1.6536418199539185
iteration: 122300, loss: 1.2588603496551514
iteration: 122350, loss: 1.1755388975143433
iteration: 122400, loss: 1.2899090051651
iteration: 122450, loss: 1.2536354064941406
iteration: 122500, loss: 1.39525306224823
iteration: 122550, loss: 2.0907540321350098
iteration: 122600, loss: 1.5257134437561035
iteration: 122650, loss: 1.3726415634155273
iteration: 122700, loss: 1.4782516956329346
iteration: 122750, loss: 1.4246275424957275
iteration: 122800, loss: 1.0106450319290161
iteration: 122850, loss: 1.332682490348816
epoch 92, loss: 1.3827436976310996
epoch 93
iteration: 122900, loss: 1.3733495473861694
iteration: 122950, loss: 1.374778151512146
iteration: 123000, loss: 1.2349573373794556
iteration: 123050, loss: 1.309786319732666
iteration: 123100, loss: 1.7447589635849
iteration: 123150, loss: 1.312451720237732
iteration: 123200, loss: 1.0269783735275269
iteration: 123250, loss: 1.3834702968597412
iteration: 123300, loss: 1.4608532190322876
iteration: 123350, loss: 1.3336338996887207
iteration: 123400, loss: 1.2806247472763062
iteration: 123450, loss: 1.335159420967102
iteration: 123500, loss: 1.3701982498168945
iteration: 123550, loss: 1.5181890726089478
iteration: 123600, loss: 1.3419808149337769
iteration: 123650, loss: 1.5636123418807983
iteration: 123700, loss: 1.1190924644470215
iteration: 123750, loss: 1.0842880010604858
iteration: 123800, loss: 1.048446536064148
iteration: 123850, loss: 1.7565431594848633
iteration: 123900, loss: 1.6485446691513062
iteration: 123950, loss: 1.1409434080123901
iteration: 124000, loss: 1.4664207696914673
iteration: 124050, loss: 1.188056230545044
iteration: 124100, loss: 1.6198004484176636
iteration: 124150, loss: 1.4891533851623535
epoch 93, loss: 1.3805909503261888
epoch 94
iteration: 124200, loss: 1.3276790380477905
iteration: 124250, loss: 0.9545156955718994
iteration: 124300, loss: 1.684854507446289
iteration: 124350, loss: 1.5426396131515503
iteration: 124400, loss: 1.4405018091201782
iteration: 124450, loss: 1.1895794868469238
iteration: 124500, loss: 0.851420521736145
iteration: 124550, loss: 1.2638782262802124
iteration: 124600, loss: 1.040697455406189
iteration: 124650, loss: 1.0148926973342896
iteration: 124700, loss: 1.6599992513656616
iteration: 124750, loss: 1.5180234909057617
iteration: 124800, loss: 1.3609306812286377
iteration: 124850, loss: 1.0159242153167725
iteration: 124900, loss: 1.4576503038406372
iteration: 124950, loss: 2.015983819961548
iteration: 125000, loss: 1.355943202972412
iteration: 125050, loss: 1.2785625457763672
iteration: 125100, loss: 1.9927819967269897
iteration: 125150, loss: 1.1436409950256348
iteration: 125200, loss: 1.2157424688339233
iteration: 125250, loss: 1.9101626873016357
iteration: 125300, loss: 2.016782760620117
iteration: 125350, loss: 1.1309767961502075
iteration: 125400, loss: 1.0565521717071533
iteration: 125450, loss: 1.376656413078308
epoch 94, loss: 1.3649413022210042
epoch 95
iteration: 125500, loss: 2.080620765686035
iteration: 125550, loss: 1.0443856716156006
iteration: 125600, loss: 1.0094660520553589
iteration: 125650, loss: 1.4837015867233276
iteration: 125700, loss: 1.2894457578659058
iteration: 125750, loss: 1.0728851556777954
iteration: 125800, loss: 1.7369742393493652
iteration: 125850, loss: 1.309525728225708
iteration: 125900, loss: 1.3960380554199219
iteration: 125950, loss: 1.5235823392868042
iteration: 126000, loss: 1.0430777072906494
iteration: 126050, loss: 1.7752476930618286
iteration: 126100, loss: 1.5941563844680786
iteration: 126150, loss: 1.1942250728607178
iteration: 126200, loss: 1.360532283782959
iteration: 126250, loss: 1.6149600744247437
iteration: 126300, loss: 1.36786949634552
iteration: 126350, loss: 1.2207599878311157
iteration: 126400, loss: 1.5993067026138306
iteration: 126450, loss: 1.581520438194275
iteration: 126500, loss: 0.95380038022995
iteration: 126550, loss: 1.4375832080841064
iteration: 126600, loss: 0.8452709913253784
iteration: 126650, loss: 1.401336669921875
iteration: 126700, loss: 1.379162073135376
iteration: 126750, loss: 1.367834210395813
iteration: 126800, loss: 1.5015522241592407
epoch 95, loss: 1.3698880796513697
epoch 96
iteration: 126850, loss: 1.1754111051559448
iteration: 126900, loss: 1.332955002784729
iteration: 126950, loss: 1.0663172006607056
iteration: 127000, loss: 1.3251944780349731
iteration: 127050, loss: 1.2933852672576904
iteration: 127100, loss: 1.0376200675964355
iteration: 127150, loss: 1.1946806907653809
iteration: 127200, loss: 1.5436513423919678
iteration: 127250, loss: 1.473167061805725
iteration: 127300, loss: 1.9200268983840942
iteration: 127350, loss: 1.097833275794983
iteration: 127400, loss: 0.978177011013031
iteration: 127450, loss: 1.2296234369277954
iteration: 127500, loss: 1.3661439418792725
iteration: 127550, loss: 1.561336874961853
iteration: 127600, loss: 1.9248719215393066
iteration: 127650, loss: 1.327946662902832
iteration: 127700, loss: 1.51759672164917
iteration: 127750, loss: 1.5240952968597412
iteration: 127800, loss: 1.334550380706787
iteration: 127850, loss: 1.368449330329895
iteration: 127900, loss: 1.4167157411575317
iteration: 127950, loss: 1.220946192741394
iteration: 128000, loss: 0.7823979258537292
iteration: 128050, loss: 1.1401567459106445
iteration: 128100, loss: 2.166400194168091
epoch 96, loss: 1.3752968784086865
epoch 97
iteration: 128150, loss: 1.401597499847412
iteration: 128200, loss: 1.3441566228866577
iteration: 128250, loss: 1.4699519872665405
iteration: 128300, loss: 1.381332278251648
iteration: 128350, loss: 1.4386508464813232
iteration: 128400, loss: 1.1480910778045654
iteration: 128450, loss: 1.1261847019195557
iteration: 128500, loss: 1.1928220987319946
iteration: 128550, loss: 1.5632964372634888
iteration: 128600, loss: 1.3155213594436646
iteration: 128650, loss: 1.1577279567718506
iteration: 128700, loss: 1.3284813165664673
iteration: 128750, loss: 1.3277329206466675
iteration: 128800, loss: 1.564056634902954
iteration: 128850, loss: 1.1365269422531128
iteration: 128900, loss: 1.6233229637145996
iteration: 128950, loss: 1.1078144311904907
iteration: 129000, loss: 1.29667329788208
iteration: 129050, loss: 1.3027350902557373
iteration: 129100, loss: 1.947822093963623
iteration: 129150, loss: 1.335742473602295
iteration: 129200, loss: 1.0785915851593018
iteration: 129250, loss: 1.806352138519287
iteration: 129300, loss: 1.6852059364318848
iteration: 129350, loss: 1.0715311765670776
iteration: 129400, loss: 1.0126075744628906
iteration: 129450, loss: 1.349658727645874
epoch 97, loss: 1.3704137952799151
epoch 98
iteration: 129500, loss: 1.3318216800689697
iteration: 129550, loss: 1.1156550645828247
iteration: 129600, loss: 1.0190902948379517
iteration: 129650, loss: 1.592891812324524
iteration: 129700, loss: 1.831289529800415
iteration: 129750, loss: 1.2600291967391968
iteration: 129800, loss: 1.0719923973083496
iteration: 129850, loss: 1.6329611539840698
iteration: 129900, loss: 1.3311598300933838
iteration: 129950, loss: 1.3691145181655884
iteration: 130000, loss: 1.196967363357544
iteration: 130050, loss: 1.2018952369689941
iteration: 130100, loss: 1.4102684259414673
iteration: 130150, loss: 1.3234213590621948
iteration: 130200, loss: 1.8186358213424683
iteration: 130250, loss: 1.1615997552871704
iteration: 130300, loss: 1.468203067779541
iteration: 130350, loss: 1.2193784713745117
iteration: 130400, loss: 1.7191364765167236
iteration: 130450, loss: 1.1526515483856201
iteration: 130500, loss: 1.1890636682510376
iteration: 130550, loss: 1.5932554006576538
iteration: 130600, loss: 1.5572868585586548
iteration: 130650, loss: 1.3929110765457153
iteration: 130700, loss: 1.44569730758667
iteration: 130750, loss: 1.176918864250183
epoch 98, loss: 1.3673254566589614
epoch 99
iteration: 130800, loss: 1.224844217300415
iteration: 130850, loss: 1.140769124031067
iteration: 130900, loss: 1.1531529426574707
iteration: 130950, loss: 1.6733918190002441
iteration: 131000, loss: 1.311186671257019
iteration: 131050, loss: 1.5062216520309448
iteration: 131100, loss: 1.07732093334198
iteration: 131150, loss: 1.3315309286117554
iteration: 131200, loss: 1.2298004627227783
iteration: 131250, loss: 1.488548994064331
iteration: 131300, loss: 1.0932453870773315
iteration: 131350, loss: 0.8990815281867981
iteration: 131400, loss: 1.5491338968276978
iteration: 131450, loss: 1.2120980024337769
iteration: 131500, loss: 2.057624578475952
iteration: 131550, loss: 1.2440216541290283
iteration: 131600, loss: 1.1670598983764648
iteration: 131650, loss: 1.3115957975387573
iteration: 131700, loss: 1.2802737951278687
iteration: 131750, loss: 1.316819667816162
iteration: 131800, loss: 1.6182336807250977
iteration: 131850, loss: 1.0927035808563232
iteration: 131900, loss: 1.5448415279388428
iteration: 131950, loss: 1.1185798645019531
iteration: 132000, loss: 1.6116783618927002
iteration: 132050, loss: 1.4792765378952026
iteration: 132100, loss: 1.2318097352981567
epoch 99, loss: 1.3730299728595659
{'accuracy': 0.5766609393189525, 'class accuracy': 0.29446269681555975, 'mean iu': 0.20319817578476582, 'fwav accuracy': 0.40957345745670887}
{'accuracy': 0.5293209112623671, 'class accuracy': 0.20388078767042567, 'mean iu': 0.13838652500803283, 'fwav accuracy': 0.35999154796164723}
